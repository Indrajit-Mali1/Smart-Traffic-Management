{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dff3342",
   "metadata": {},
   "source": [
    "# Final Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb290ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "import math\n",
    "from tracker import Tracker\n",
    "\n",
    "# Load YOLO model\n",
    "model = YOLO('yolo12n.pt')  # Update with correct model path\n",
    "\n",
    "# Video file paths\n",
    "video_paths = [\n",
    "    'traffic1.mp4',  # North\n",
    "    'traffic2.mp4',  # East\n",
    "    'traffic3.mp4',  # South\n",
    "    'traffic4.mp4'   # West\n",
    "]\n",
    "\n",
    "# Load videos and check if they opened successfully\n",
    "videos = []\n",
    "for i, path in enumerate(video_paths):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video {path}\")\n",
    "        exit(1)\n",
    "    videos.append(cap)\n",
    "\n",
    "# Class list for vehicle types (subset of COCO classes)\n",
    "class_list = ['bicycle', 'car', 'motorcycle', 'bus', 'truck']\n",
    "valid_class_ids = [1, 2, 3, 6, 8]  # COCO indices: bicycle, car, motorcycle, bus, truck\n",
    "\n",
    "# Tracker instance\n",
    "tracker = Tracker()\n",
    "\n",
    "# Signal states: 0=Red, 1=Green, 2=Yellow\n",
    "signal_states = [1, 0, 0, 0]  # Start with frame 0 (North) green\n",
    "timers = [60, 0, 0, 0]  # Initial timer for green (60s), others to be calculated\n",
    "current_frame = 0  # Start with frame 0\n",
    "last_switch_time = time.time()\n",
    "\n",
    "def draw_signals():\n",
    "    signal_frame = np.zeros((400, 800, 3), dtype=np.uint8)\n",
    "    colors = [(0, 0, 255), (0, 255, 0), (0, 255, 255)]  # Red, Green, Yellow\n",
    "    for i in range(4):\n",
    "        x, y = (i % 2) * 400, (i // 2) * 200\n",
    "        state = signal_states[i]\n",
    "        cv2.circle(signal_frame, (x + 50, y + 50), 40, colors[state], -1)\n",
    "        # Display timer as integer\n",
    "        cv2.putText(signal_frame, f\"{int(timers[i])}s\", (x + 20, y + 150), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "    return signal_frame\n",
    "\n",
    "def calculate_max_distance_and_draw(frame, scan=True):\n",
    "    if not scan:\n",
    "        return frame, 0\n",
    "    \n",
    "    results = model.predict(frame, verbose=False)\n",
    "    max_dist = 0\n",
    "    objects_rect = []\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes.xyxy.cpu().numpy()\n",
    "        classes = r.boxes.cls.cpu().numpy()\n",
    "        for box, cls in zip(boxes, classes):\n",
    "            cls = int(cls)\n",
    "            if cls not in valid_class_ids:\n",
    "                continue\n",
    "            \n",
    "            class_idx = valid_class_ids.index(cls)\n",
    "            class_name = class_list[class_idx]\n",
    "            \n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            objects_rect.append([x1, y1, w, h])\n",
    "            \n",
    "            dist = frame.shape[0] - y1\n",
    "            max_dist = max(max_dist, dist)\n",
    "\n",
    "    tracked_objects = tracker.update(objects_rect)\n",
    "    \n",
    "    for obj in tracked_objects:\n",
    "        x, y, w, h, obj_id = obj\n",
    "        for box in boxes:\n",
    "            bx1, by1, bx2, by2 = map(int, box)\n",
    "            if bx1 == x and by1 == y:\n",
    "                for cls in classes:\n",
    "                    if int(cls) in valid_class_ids:\n",
    "                        class_idx = valid_class_ids.index(int(cls))\n",
    "                        class_name = class_list[class_idx]\n",
    "                        break\n",
    "                break\n",
    "        label = f\"{class_name} ID:{obj_id}\"\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, label, (x, y - 10), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    \n",
    "    return frame, max_dist\n",
    "\n",
    "def update_timers(max_distances):\n",
    "    global timers, signal_states, current_frame, last_switch_time\n",
    "    current_time = time.time()\n",
    "    elapsed = current_time - last_switch_time\n",
    "\n",
    "    # Update timers for green and yellow\n",
    "    for i in range(4):\n",
    "        if signal_states[i] in [1, 2]:  # Green or Yellow\n",
    "            timers[i] = max(0, timers[i] - elapsed)\n",
    "\n",
    "    # Handle state transitions\n",
    "    if signal_states[current_frame] == 1 and timers[current_frame] <= 0:\n",
    "        signal_states[current_frame] = 2  # Green to Yellow\n",
    "        timers[current_frame] = 5  # Yellow for 5 seconds\n",
    "    elif signal_states[current_frame] == 2 and timers[current_frame] <= 0:\n",
    "        signal_states[current_frame] = 0  # Yellow to Red\n",
    "        current_frame = (current_frame + 1) % 4  # Move to next frame\n",
    "        signal_states[current_frame] = 1  # Next frame to Green\n",
    "        max_dist = max_distances[current_frame]\n",
    "        green_duration = 60 if max_dist > 250 else max(6, (max_dist // 25) * 6)\n",
    "        timers[current_frame] = green_duration\n",
    "\n",
    "    # Calculate red light timers (time until green)\n",
    "    total_cycle_time = 0\n",
    "    for i in range(4):\n",
    "        if signal_states[i] == 1:  # Green\n",
    "            total_cycle_time += timers[i] + 5  # Remaining green + yellow\n",
    "        elif signal_states[i] == 2:  # konserwYellow\n",
    "            total_cycle_time += timers[i]  # Remaining yellow\n",
    "\n",
    "    for i in range(1, 4):  # Calculate for red lights ahead in sequence\n",
    "        idx = (current_frame + i) % 4\n",
    "        if signal_states[idx] == 0:  # Red\n",
    "            wait_time = total_cycle_time\n",
    "            for j in range(i):\n",
    "                prev_idx = (current_frame + j) % 4\n",
    "                if prev_idx != current_frame:  # Skip current green/yellow\n",
    "                    max_dist = max_distances[prev_idx]\n",
    "                    green_duration = 60 if max_dist > 250 else max(6, (max_dist // 25) * 6)\n",
    "                    wait_time += green_duration + 5  # Add green + yellow for each prior frame\n",
    "            timers[idx] = wait_time\n",
    "\n",
    "    # Debug output with integer timers\n",
    "    print(f\"Frame: {current_frame}, States: {signal_states}, Timers: {[int(t) for t in timers]}\")\n",
    "    last_switch_time = current_time\n",
    "\n",
    "while True:\n",
    "    frames = []\n",
    "    max_distances = []\n",
    "    for i, cap in enumerate(videos):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(f\"Warning: Failed to read frame from video {video_paths[i]}. Attempting to loop.\")\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(f\"Error: Could not loop video {video_paths[i]}. Exiting.\")\n",
    "                exit(1)\n",
    "        \n",
    "        if frame is None or frame.size == 0:\n",
    "            print(f\"Error: Invalid frame from video {video_paths[i]}. Exiting.\")\n",
    "            exit(1)\n",
    "        \n",
    "        frame = cv2.resize(frame, (400, 300))\n",
    "        \n",
    "        scan = signal_states[i] != 1\n",
    "        frame, max_dist = calculate_max_distance_and_draw(frame, scan)\n",
    "        max_distances.append(max_dist)\n",
    "        \n",
    "        cv2.putText(frame, f\"Max Dist: {max_dist:.0f}px\", (10, 30), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        frames.append(frame)\n",
    "\n",
    "    update_timers(max_distances)\n",
    "\n",
    "    top_row = np.hstack((frames[0], frames[1]))\n",
    "    bottom_row = np.hstack((frames[2], frames[3]))\n",
    "    video_grid = np.vstack((top_row, bottom_row))\n",
    "\n",
    "    signal_grid = draw_signals()\n",
    "\n",
    "    cv2.imshow('Traffic Videos', video_grid)\n",
    "    cv2.imshow('Traffic Signals', signal_grid)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "for cap in videos:\n",
    "    cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
