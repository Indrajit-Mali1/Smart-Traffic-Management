{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6778017e",
   "metadata": {},
   "source": [
    "# Practice Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae3cdd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "from tracker import*\n",
    "\n",
    "model=YOLO('yolo12n.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5022a990-359b-4d2b-b8d8-8d67c83c8f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('traffic.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfc62f7d-785f-4078-a922-625516fafe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20bc3265-b916-4ccb-8671-aa49a3e8049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker=Tracker()\n",
    "count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "835ce333",
   "metadata": {},
   "outputs": [],
   "source": [
    "down={}\n",
    "up={}\n",
    "\n",
    "counter_down=[]\n",
    "counter_up=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c2c15c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "503d7416-864f-42b3-9c30-b7273db6ec65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x320 1 person, 13 cars, 2 buss, 8874.2ms\n",
      "Speed: 463.1ms preprocess, 8874.2ms inference, 337.2ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x320 1 person, 13 cars, 2 buss, 5008.5ms\n",
      "Speed: 81.2ms preprocess, 5008.5ms inference, 17.7ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x320 13 cars, 2 buss, 3401.8ms\n",
      "Speed: 24.9ms preprocess, 3401.8ms inference, 24.9ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x320 13 cars, 2 buss, 3599.2ms\n",
      "Speed: 55.5ms preprocess, 3599.2ms inference, 31.9ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x320 13 cars, 2 buss, 3126.3ms\n",
      "Speed: 26.6ms preprocess, 3126.3ms inference, 137.3ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x320 1 person, 12 cars, 2 buss, 3625.7ms\n",
      "Speed: 70.8ms preprocess, 3625.7ms inference, 9.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x320 1 person, 12 cars, 2 buss, 3862.2ms\n",
      "Speed: 69.7ms preprocess, 3862.2ms inference, 15.2ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x320 1 person, 12 cars, 2 buss, 3771.6ms\n",
      "Speed: 39.2ms preprocess, 3771.6ms inference, 26.9ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x320 12 cars, 2 buss, 3626.2ms\n",
      "Speed: 81.6ms preprocess, 3626.2ms inference, 7.1ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x320 1 person, 12 cars, 2 buss, 3571.0ms\n",
      "Speed: 30.3ms preprocess, 3571.0ms inference, 22.7ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x320 1 person, 14 cars, 2 buss, 3067.9ms\n",
      "Speed: 81.5ms preprocess, 3067.9ms inference, 30.9ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x320 1 person, 14 cars, 2 buss, 3125.9ms\n",
      "Speed: 58.1ms preprocess, 3125.9ms inference, 24.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x320 13 cars, 2 buss, 3007.0ms\n",
      "Speed: 42.8ms preprocess, 3007.0ms inference, 22.4ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x320 13 cars, 2 buss, 3739.0ms\n",
      "Speed: 64.4ms preprocess, 3739.0ms inference, 52.6ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x320 1 person, 12 cars, 2 buss, 3182.1ms\n",
      "Speed: 45.9ms preprocess, 3182.1ms inference, 18.7ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x320 1 person, 12 cars, 2 buss, 3185.7ms\n",
      "Speed: 24.6ms preprocess, 3185.7ms inference, 45.8ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x320 1 person, 12 cars, 2 buss, 3080.5ms\n",
      "Speed: 19.2ms preprocess, 3080.5ms inference, 30.2ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x320 1 person, 12 cars, 2 buss, 3158.5ms\n",
      "Speed: 52.4ms preprocess, 3158.5ms inference, 24.5ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x320 1 person, 12 cars, 2 buss, 2811.0ms\n",
      "Speed: 28.8ms preprocess, 2811.0ms inference, 31.2ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x320 1 person, 12 cars, 2 buss, 3365.4ms\n",
      "Speed: 36.3ms preprocess, 3365.4ms inference, 23.6ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x320 13 cars, 2 buss, 2890.8ms\n",
      "Speed: 36.6ms preprocess, 2890.8ms inference, 33.5ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x320 1 person, 13 cars, 2 buss, 3321.8ms\n",
      "Speed: 49.7ms preprocess, 3321.8ms inference, 23.9ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x320 1 person, 13 cars, 2 buss, 2925.1ms\n",
      "Speed: 40.7ms preprocess, 2925.1ms inference, 27.6ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x320 1 person, 13 cars, 2 buss, 2960.7ms\n",
      "Speed: 27.6ms preprocess, 2960.7ms inference, 33.4ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x320 1 person, 12 cars, 2 buss, 3351.3ms\n",
      "Speed: 31.0ms preprocess, 3351.3ms inference, 18.2ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x320 1 person, 12 cars, 2 buss, 3409.5ms\n",
      "Speed: 14.5ms preprocess, 3409.5ms inference, 42.1ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x320 1 person, 13 cars, 2 buss, 2859.4ms\n",
      "Speed: 31.3ms preprocess, 2859.4ms inference, 26.8ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x320 2 persons, 13 cars, 2 buss, 2857.2ms\n",
      "Speed: 31.1ms preprocess, 2857.2ms inference, 21.2ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x320 13 cars, 2 buss, 3078.7ms\n",
      "Speed: 28.1ms preprocess, 3078.7ms inference, 31.8ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x320 1 person, 13 cars, 2 buss, 2897.3ms\n",
      "Speed: 22.8ms preprocess, 2897.3ms inference, 7.0ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x320 13 cars, 2 buss, 3170.2ms\n",
      "Speed: 56.1ms preprocess, 3170.2ms inference, 17.1ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x320 13 cars, 2 buss, 3093.7ms\n",
      "Speed: 18.5ms preprocess, 3093.7ms inference, 28.2ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x320 1 person, 13 cars, 2 buss, 3052.9ms\n",
      "Speed: 37.4ms preprocess, 3052.9ms inference, 7.1ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x320 13 cars, 2 buss, 3080.3ms\n",
      "Speed: 192.9ms preprocess, 3080.3ms inference, 45.4ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x320 14 cars, 2 buss, 3162.3ms\n",
      "Speed: 36.0ms preprocess, 3162.3ms inference, 18.5ms postprocess per image at shape (1, 3, 640, 320)\n",
      "\n",
      "0: 640x320 1 person, 13 cars, 2 buss, 3020.3ms\n",
      "Speed: 32.6ms preprocess, 3020.3ms inference, 30.6ms postprocess per image at shape (1, 3, 640, 320)\n"
     ]
    }
   ],
   "source": [
    "while True:    \n",
    "    ret,frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    count += 1\n",
    "    frame=cv2.resize(frame,(360,720))\n",
    "   \n",
    "\n",
    "    results=model.predict(frame)\n",
    " #   print(results)\n",
    "    a=results[0].boxes.data\n",
    "    a = a.detach().cpu().numpy()  # added this line\n",
    "    px=pd.DataFrame(a).astype(\"float\")\n",
    "    #print(px)\n",
    "\n",
    "    list=[]\n",
    "             \n",
    "    for index,row in px.iterrows():\n",
    "#        print(row) \n",
    "        x1=int(row[0])\n",
    "        y1=int(row[1])\n",
    "        x2=int(row[2])\n",
    "        y2=int(row[3])\n",
    "        d=int(row[5])\n",
    "        c=class_list[d]\n",
    "        if 'car' in c:\n",
    "            list.append([x1,y1,x2,y2])\n",
    "            #print(c)\n",
    "\n",
    "    bbox_id=tracker.update(list)\n",
    "    #print(bbox_id)\n",
    "    for bbox in bbox_id:\n",
    "        x3,y3,x4,y4,id=bbox\n",
    "        cx=int(x3+x4)//2\n",
    "        cy=int(y3+y4)//2\n",
    "\n",
    "        red_line_y=198\n",
    "        blue_line_y=268   \n",
    "        offset = 7\n",
    "\n",
    "    for bbox in bbox_id:\n",
    "      \n",
    "        x3, y3, x4, y4, id = bbox\n",
    "\n",
    "        # Draw Rectangle\n",
    "        cv2.rectangle(frame, (x3, y3), (x4, y4), (255, 0, 255), 2)\n",
    "\n",
    "        # Put ID Text\n",
    "        # cv2.putText(frame, f'ID {id}', (x3, y3 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)    \n",
    "        \n",
    "  \n",
    "\n",
    "    #     ''' both lines combined condition . First condition is for red line'''\n",
    "    #     ## condition for counting the cars which are entering from red line and exiting from blue line\n",
    "    #     if red_line_y < (cy + offset) and red_line_y > (cy - offset):\n",
    "    #       down[id]=cy   \n",
    "    #     if id in down:\n",
    "    #        if blue_line_y < (cy + offset) and blue_line_y > (cy - offset):         \n",
    "    #          cv2.circle(frame,(cx,cy),4,(0,0,255),-1)\n",
    "    #          cv2.putText(frame,str(id),(cx,cy),cv2.FONT_HERSHEY_COMPLEX,0.8,(0,255,255),2)\n",
    "    #          #counter+=1\n",
    "    #          counter_down.append(id)  # get a list of the cars and buses which are entering the line red and exiting the line blue\n",
    "\n",
    "    #     # condition for cars entering from  blue line\n",
    "    #     if blue_line_y < (cy + offset) and blue_line_y > (cy - offset):\n",
    "    #       up[id]=cy   \n",
    "    #     if id in up:\n",
    "    #        if red_line_y < (cy + offset) and red_line_y > (cy - offset):         \n",
    "    #          cv2.circle(frame,(cx,cy),4,(0,0,255),-1)\n",
    "    #          cv2.putText(frame,str(id),(cx,cy),cv2.FONT_HERSHEY_COMPLEX,0.8,(0,255,255),2)\n",
    "    #          #counter+=1\n",
    "    #          counter_up.append(id)  # get a list of the cars which are entering the line 1 and exiting the line 2 \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # text_color = (255,255,255)  # white color for text\n",
    "    # red_color = (0, 0, 255)  # (B, G, R)   \n",
    "    # blue_color = (255, 0, 0)  # (B, G, R)\n",
    "    # green_color = (0, 255, 0)  # (B, G, R)  \n",
    "\n",
    "    # cv2.line(frame,(172,198),(774,198),red_color,3)  #  starting cordinates and end of line cordinates\n",
    "    # cv2.putText(frame,('red line'),(172,198),cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1, cv2.LINE_AA)\n",
    "    \n",
    "    # cv2.line(frame,(8,268),(927,268),blue_color,3)  # seconde line\n",
    "    # cv2.putText(frame,('blue line'),(8,268),cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1, cv2.LINE_AA)    \n",
    "\n",
    "\n",
    "    # downwards = (len(counter_down))\n",
    "    # cv2.putText(frame,('going down - ')+ str(downwards),(60,40),cv2.FONT_HERSHEY_SIMPLEX, 0.5, green_color, 1, cv2.LINE_AA)    \n",
    "\n",
    "    \n",
    "    # upwards = (len(counter_up))\n",
    "    # cv2.putText(frame,('going up - ')+ str(upwards),(60,60),cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1, cv2.LINE_AA)  \n",
    "\n",
    "    cv2.imshow(\"frames\", frame)\n",
    "    if cv2.waitKey(1)&0xFF==27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6839ef4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 18 cars, 1 truck, 451.7ms\n",
      "Speed: 8.3ms preprocess, 451.7ms inference, 5.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 25 persons, 33 cars, 1 motorcycle, 1 bus, 13 trucks, 453.7ms\n",
      "Speed: 7.6ms preprocess, 453.7ms inference, 4.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 25 persons, 19 cars, 4 motorcycles, 522.7ms\n",
      "Speed: 7.2ms preprocess, 522.7ms inference, 5.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 519.4ms\n",
      "Speed: 5.8ms preprocess, 519.4ms inference, 5.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 23 cars, 1 motorcycle, 2 trucks, 586.2ms\n",
      "Speed: 21.8ms preprocess, 586.2ms inference, 4.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 26 persons, 29 cars, 1 motorcycle, 2 buss, 12 trucks, 482.8ms\n",
      "Speed: 5.6ms preprocess, 482.8ms inference, 4.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 21 persons, 2 bicycles, 22 cars, 6 motorcycles, 483.1ms\n",
      "Speed: 5.4ms preprocess, 483.1ms inference, 4.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 motorcycle, 537.0ms\n",
      "Speed: 6.5ms preprocess, 537.0ms inference, 6.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 23 cars, 1 motorcycle, 1 bus, 2 trucks, 603.8ms\n",
      "Speed: 6.7ms preprocess, 603.8ms inference, 5.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 25 persons, 28 cars, 1 motorcycle, 2 buss, 10 trucks, 685.0ms\n",
      "Speed: 9.0ms preprocess, 685.0ms inference, 8.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 2 cars, 618.8ms\n",
      "Speed: 7.9ms preprocess, 618.8ms inference, 4.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 truck, 467.3ms\n",
      "Speed: 7.2ms preprocess, 467.3ms inference, 5.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 23 cars, 1 motorcycle, 1 truck, 445.4ms\n",
      "Speed: 7.7ms preprocess, 445.4ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 466.2ms\n",
      "Speed: 7.3ms preprocess, 466.2ms inference, 5.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 438.2ms\n",
      "Speed: 7.3ms preprocess, 438.2ms inference, 4.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 1 motorcycle, 433.2ms\n",
      "Speed: 7.9ms preprocess, 433.2ms inference, 5.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 24 cars, 1 motorcycle, 1 truck, 410.0ms\n",
      "Speed: 5.4ms preprocess, 410.0ms inference, 4.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 431.3ms\n",
      "Speed: 9.9ms preprocess, 431.3ms inference, 5.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 31 persons, 24 cars, 6 motorcycles, 407.9ms\n",
      "Speed: 5.5ms preprocess, 407.9ms inference, 4.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 23 persons, 16 cars, 24 motorcycles, 3 trucks, 422.3ms\n",
      "Speed: 6.7ms preprocess, 422.3ms inference, 4.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 22 cars, 1 motorcycle, 4 trucks, 421.8ms\n",
      "Speed: 4.7ms preprocess, 421.8ms inference, 6.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 25 persons, 30 cars, 4 motorcycles, 2 buss, 11 trucks, 428.9ms\n",
      "Speed: 6.2ms preprocess, 428.9ms inference, 4.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 24 persons, 26 cars, 4 motorcycles, 425.8ms\n",
      "Speed: 5.8ms preprocess, 425.8ms inference, 4.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 23 persons, 16 cars, 23 motorcycles, 3 trucks, 414.2ms\n",
      "Speed: 6.4ms preprocess, 414.2ms inference, 4.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 25 cars, 1 motorcycle, 2 buss, 2 trucks, 407.8ms\n",
      "Speed: 4.9ms preprocess, 407.8ms inference, 4.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 24 persons, 28 cars, 2 motorcycles, 2 buss, 11 trucks, 425.4ms\n",
      "Speed: 6.8ms preprocess, 425.4ms inference, 4.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 405.9ms\n",
      "Speed: 6.0ms preprocess, 405.9ms inference, 5.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 21 persons, 16 cars, 23 motorcycles, 3 trucks, 415.7ms\n",
      "Speed: 7.2ms preprocess, 415.7ms inference, 4.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 24 cars, 1 motorcycle, 1 bus, 1 truck, 431.0ms\n",
      "Speed: 5.7ms preprocess, 431.0ms inference, 4.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 410.5ms\n",
      "Speed: 7.5ms preprocess, 410.5ms inference, 4.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 417.3ms\n",
      "Speed: 6.9ms preprocess, 417.3ms inference, 4.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 405.6ms\n",
      "Speed: 6.8ms preprocess, 405.6ms inference, 5.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 24 cars, 1 motorcycle, 2 buss, 438.5ms\n",
      "Speed: 5.9ms preprocess, 438.5ms inference, 4.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 25 persons, 24 cars, 1 motorcycle, 2 buss, 12 trucks, 444.8ms\n",
      "Speed: 6.2ms preprocess, 444.8ms inference, 3.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 2 cars, 414.6ms\n",
      "Speed: 5.7ms preprocess, 414.6ms inference, 4.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 20 persons, 16 cars, 23 motorcycles, 3 trucks, 449.8ms\n",
      "Speed: 7.9ms preprocess, 449.8ms inference, 4.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 477.4ms\n",
      "Speed: 5.2ms preprocess, 477.4ms inference, 39.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 24 persons, 25 cars, 2 motorcycles, 1 bus, 14 trucks, 415.5ms\n",
      "Speed: 5.7ms preprocess, 415.5ms inference, 4.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 27 persons, 25 cars, 10 motorcycles, 420.2ms\n",
      "Speed: 6.1ms preprocess, 420.2ms inference, 4.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 19 persons, 16 cars, 21 motorcycles, 3 trucks, 414.0ms\n",
      "Speed: 6.5ms preprocess, 414.0ms inference, 4.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 21 cars, 1 motorcycle, 2 buss, 1 truck, 421.5ms\n",
      "Speed: 8.9ms preprocess, 421.5ms inference, 4.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 21 persons, 29 cars, 4 motorcycles, 1 bus, 13 trucks, 432.9ms\n",
      "Speed: 6.4ms preprocess, 432.9ms inference, 4.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 25 persons, 26 cars, 8 motorcycles, 400.3ms\n",
      "Speed: 6.0ms preprocess, 400.3ms inference, 5.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 19 persons, 16 cars, 22 motorcycles, 3 trucks, 417.4ms\n",
      "Speed: 6.0ms preprocess, 417.4ms inference, 4.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 25 cars, 1 motorcycle, 1 bus, 2 trucks, 407.3ms\n",
      "Speed: 5.3ms preprocess, 407.3ms inference, 4.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 20 persons, 28 cars, 3 motorcycles, 1 bus, 13 trucks, 423.0ms\n",
      "Speed: 7.1ms preprocess, 423.0ms inference, 5.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 25 persons, 1 bicycle, 25 cars, 10 motorcycles, 428.3ms\n",
      "Speed: 7.9ms preprocess, 428.3ms inference, 4.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 21 persons, 16 cars, 25 motorcycles, 3 trucks, 422.7ms\n",
      "Speed: 7.7ms preprocess, 422.7ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 28 cars, 1 motorcycle, 2 trucks, 422.8ms\n",
      "Speed: 5.9ms preprocess, 422.8ms inference, 4.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 21 persons, 27 cars, 3 motorcycles, 1 bus, 15 trucks, 419.3ms\n",
      "Speed: 6.1ms preprocess, 419.3ms inference, 3.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 411.8ms\n",
      "Speed: 6.0ms preprocess, 411.8ms inference, 3.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 21 persons, 16 cars, 23 motorcycles, 1 bus, 3 trucks, 400.7ms\n",
      "Speed: 7.2ms preprocess, 400.7ms inference, 4.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 24 cars, 2 motorcycles, 3 trucks, 497.3ms\n",
      "Speed: 4.5ms preprocess, 497.3ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 23 persons, 32 cars, 3 motorcycles, 1 bus, 10 trucks, 426.2ms\n",
      "Speed: 6.2ms preprocess, 426.2ms inference, 4.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 414.3ms\n",
      "Speed: 6.3ms preprocess, 414.3ms inference, 4.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 20 persons, 16 cars, 24 motorcycles, 1 bus, 3 trucks, 410.1ms\n",
      "Speed: 7.6ms preprocess, 410.1ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 407.7ms\n",
      "Speed: 5.6ms preprocess, 407.7ms inference, 5.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 23 persons, 28 cars, 2 motorcycles, 1 bus, 8 trucks, 412.6ms\n",
      "Speed: 8.1ms preprocess, 412.6ms inference, 5.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 421.6ms\n",
      "Speed: 6.8ms preprocess, 421.6ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 19 persons, 16 cars, 22 motorcycles, 1 bus, 3 trucks, 403.5ms\n",
      "Speed: 7.6ms preprocess, 403.5ms inference, 3.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 26 cars, 1 motorcycle, 3 trucks, 410.5ms\n",
      "Speed: 4.9ms preprocess, 410.5ms inference, 5.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 26 persons, 31 cars, 5 motorcycles, 1 bus, 10 trucks, 430.8ms\n",
      "Speed: 6.7ms preprocess, 430.8ms inference, 4.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 410.8ms\n",
      "Speed: 5.4ms preprocess, 410.8ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 19 persons, 16 cars, 20 motorcycles, 1 bus, 3 trucks, 414.2ms\n",
      "Speed: 7.0ms preprocess, 414.2ms inference, 4.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 26 cars, 3 motorcycles, 1 bus, 3 trucks, 403.8ms\n",
      "Speed: 5.2ms preprocess, 403.8ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 27 persons, 30 cars, 5 motorcycles, 1 bus, 11 trucks, 426.6ms\n",
      "Speed: 7.3ms preprocess, 426.6ms inference, 4.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 26 persons, 25 cars, 7 motorcycles, 414.1ms\n",
      "Speed: 5.7ms preprocess, 414.1ms inference, 4.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 18 persons, 16 cars, 22 motorcycles, 1 bus, 3 trucks, 417.9ms\n",
      "Speed: 5.8ms preprocess, 417.9ms inference, 4.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 25 cars, 2 motorcycles, 1 bus, 2 trucks, 428.3ms\n",
      "Speed: 8.6ms preprocess, 428.3ms inference, 3.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 22 persons, 28 cars, 5 motorcycles, 1 bus, 13 trucks, 416.7ms\n",
      "Speed: 6.6ms preprocess, 416.7ms inference, 4.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 407.0ms\n",
      "Speed: 6.8ms preprocess, 407.0ms inference, 4.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 20 persons, 16 cars, 21 motorcycles, 1 bus, 3 trucks, 406.7ms\n",
      "Speed: 9.4ms preprocess, 406.7ms inference, 5.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 26 cars, 2 motorcycles, 2 trucks, 412.7ms\n",
      "Speed: 5.7ms preprocess, 412.7ms inference, 3.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 24 persons, 26 cars, 2 motorcycles, 2 buss, 12 trucks, 417.7ms\n",
      "Speed: 5.1ms preprocess, 417.7ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 23 persons, 26 cars, 5 motorcycles, 419.6ms\n",
      "Speed: 6.5ms preprocess, 419.6ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 19 persons, 16 cars, 24 motorcycles, 3 trucks, 423.9ms\n",
      "Speed: 7.3ms preprocess, 423.9ms inference, 4.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 23 cars, 1 motorcycle, 1 bus, 2 trucks, 410.9ms\n",
      "Speed: 5.7ms preprocess, 410.9ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 21 persons, 32 cars, 5 motorcycles, 1 bus, 10 trucks, 411.4ms\n",
      "Speed: 7.7ms preprocess, 411.4ms inference, 4.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 2 cars, 574.9ms\n",
      "Speed: 5.8ms preprocess, 574.9ms inference, 4.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 20 persons, 17 cars, 22 motorcycles, 3 trucks, 453.7ms\n",
      "Speed: 6.9ms preprocess, 453.7ms inference, 5.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 21 cars, 3 motorcycles, 1 bus, 1 truck, 419.5ms\n",
      "Speed: 6.1ms preprocess, 419.5ms inference, 4.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 21 persons, 28 cars, 4 motorcycles, 2 buss, 11 trucks, 448.8ms\n",
      "Speed: 7.4ms preprocess, 448.8ms inference, 4.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 26 persons, 22 cars, 7 motorcycles, 407.9ms\n",
      "Speed: 5.2ms preprocess, 407.9ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 22 persons, 16 cars, 23 motorcycles, 3 trucks, 401.9ms\n",
      "Speed: 6.2ms preprocess, 401.9ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 23 cars, 3 motorcycles, 1 bus, 1 truck, 407.3ms\n",
      "Speed: 5.7ms preprocess, 407.3ms inference, 4.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 24 persons, 27 cars, 3 motorcycles, 2 buss, 12 trucks, 433.2ms\n",
      "Speed: 6.4ms preprocess, 433.2ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 423.0ms\n",
      "Speed: 4.2ms preprocess, 423.0ms inference, 3.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 20 persons, 16 cars, 22 motorcycles, 2 trucks, 412.2ms\n",
      "Speed: 8.2ms preprocess, 412.2ms inference, 4.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 24 cars, 2 motorcycles, 1 bus, 1 truck, 411.7ms\n",
      "Speed: 5.3ms preprocess, 411.7ms inference, 4.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 23 persons, 27 cars, 2 motorcycles, 1 bus, 10 trucks, 416.5ms\n",
      "Speed: 6.6ms preprocess, 416.5ms inference, 4.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 413.6ms\n",
      "Speed: 5.5ms preprocess, 413.6ms inference, 3.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 22 persons, 16 cars, 25 motorcycles, 2 trucks, 416.3ms\n",
      "Speed: 5.8ms preprocess, 416.3ms inference, 4.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 23 cars, 2 motorcycles, 2 buss, 1 truck, 406.1ms\n",
      "Speed: 5.6ms preprocess, 406.1ms inference, 4.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 26 persons, 33 cars, 3 motorcycles, 1 bus, 9 trucks, 420.6ms\n",
      "Speed: 6.2ms preprocess, 420.6ms inference, 5.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 3 cars, 421.9ms\n",
      "Speed: 6.8ms preprocess, 421.9ms inference, 4.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 23 persons, 15 cars, 23 motorcycles, 2 trucks, 402.3ms\n",
      "Speed: 6.9ms preprocess, 402.3ms inference, 5.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 421.1ms\n",
      "Speed: 4.6ms preprocess, 421.1ms inference, 4.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 22 persons, 32 cars, 4 motorcycles, 1 bus, 13 trucks, 440.6ms\n",
      "Speed: 6.4ms preprocess, 440.6ms inference, 5.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 414.3ms\n",
      "Speed: 7.8ms preprocess, 414.3ms inference, 4.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 20 persons, 15 cars, 25 motorcycles, 2 trucks, 406.0ms\n",
      "Speed: 8.5ms preprocess, 406.0ms inference, 4.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 25 cars, 1 bus, 1 truck, 418.6ms\n",
      "Speed: 5.3ms preprocess, 418.6ms inference, 5.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 23 persons, 33 cars, 3 motorcycles, 2 buss, 9 trucks, 428.6ms\n",
      "Speed: 8.1ms preprocess, 428.6ms inference, 4.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 412.9ms\n",
      "Speed: 5.9ms preprocess, 412.9ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 19 persons, 15 cars, 29 motorcycles, 2 trucks, 405.9ms\n",
      "Speed: 5.6ms preprocess, 405.9ms inference, 3.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 420.9ms\n",
      "Speed: 6.1ms preprocess, 420.9ms inference, 4.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 25 persons, 30 cars, 2 motorcycles, 3 buss, 9 trucks, 464.4ms\n",
      "Speed: 8.7ms preprocess, 464.4ms inference, 3.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 413.9ms\n",
      "Speed: 6.0ms preprocess, 413.9ms inference, 3.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 19 persons, 16 cars, 27 motorcycles, 2 trucks, 411.0ms\n",
      "Speed: 7.1ms preprocess, 411.0ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 418.9ms\n",
      "Speed: 5.9ms preprocess, 418.9ms inference, 3.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 28 persons, 27 cars, 3 motorcycles, 2 buss, 8 trucks, 402.7ms\n",
      "Speed: 6.5ms preprocess, 402.7ms inference, 4.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 2 cars, 406.3ms\n",
      "Speed: 5.7ms preprocess, 406.3ms inference, 4.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 20 persons, 17 cars, 22 motorcycles, 1 bus, 2 trucks, 407.2ms\n",
      "Speed: 6.8ms preprocess, 407.2ms inference, 5.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 23 cars, 3 motorcycles, 1 bus, 1 truck, 453.1ms\n",
      "Speed: 6.2ms preprocess, 453.1ms inference, 4.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 29 persons, 29 cars, 2 motorcycles, 2 buss, 14 trucks, 433.9ms\n",
      "Speed: 6.2ms preprocess, 433.9ms inference, 4.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 421.3ms\n",
      "Speed: 5.8ms preprocess, 421.3ms inference, 4.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 21 persons, 16 cars, 21 motorcycles, 1 bus, 2 trucks, 1 traffic light, 425.4ms\n",
      "Speed: 8.2ms preprocess, 425.4ms inference, 5.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 409.0ms\n",
      "Speed: 5.8ms preprocess, 409.0ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 29 persons, 32 cars, 4 motorcycles, 2 buss, 8 trucks, 412.6ms\n",
      "Speed: 7.6ms preprocess, 412.6ms inference, 4.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 413.9ms\n",
      "Speed: 5.6ms preprocess, 413.9ms inference, 5.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 2 cars, 410.1ms\n",
      "Speed: 10.2ms preprocess, 410.1ms inference, 6.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 24 cars, 1 motorcycle, 1 truck, 420.2ms\n",
      "Speed: 7.3ms preprocess, 420.2ms inference, 4.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 24 persons, 26 cars, 2 motorcycles, 1 bus, 7 trucks, 425.2ms\n",
      "Speed: 6.2ms preprocess, 425.2ms inference, 4.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 409.1ms\n",
      "Speed: 7.0ms preprocess, 409.1ms inference, 5.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 17 persons, 15 cars, 24 motorcycles, 1 bus, 2 trucks, 1 traffic light, 415.3ms\n",
      "Speed: 7.1ms preprocess, 415.3ms inference, 4.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 25 cars, 2 motorcycles, 1 truck, 419.0ms\n",
      "Speed: 4.7ms preprocess, 419.0ms inference, 5.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 25 persons, 25 cars, 3 motorcycles, 1 bus, 11 trucks, 434.5ms\n",
      "Speed: 7.8ms preprocess, 434.5ms inference, 4.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 420.6ms\n",
      "Speed: 5.7ms preprocess, 420.6ms inference, 4.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 person, 418.2ms\n",
      "Speed: 8.6ms preprocess, 418.2ms inference, 4.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 27 cars, 3 motorcycles, 1 bus, 1 truck, 420.8ms\n",
      "Speed: 6.2ms preprocess, 420.8ms inference, 4.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 25 persons, 27 cars, 3 motorcycles, 1 bus, 10 trucks, 437.6ms\n",
      "Speed: 6.1ms preprocess, 437.6ms inference, 4.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 418.1ms\n",
      "Speed: 5.6ms preprocess, 418.1ms inference, 4.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 20 persons, 17 cars, 25 motorcycles, 2 buss, 3 trucks, 1 traffic light, 406.9ms\n",
      "Speed: 8.9ms preprocess, 406.9ms inference, 4.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 25 cars, 1 motorcycle, 1 truck, 428.0ms\n",
      "Speed: 5.6ms preprocess, 428.0ms inference, 3.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 25 persons, 29 cars, 2 motorcycles, 1 bus, 6 trucks, 425.3ms\n",
      "Speed: 6.0ms preprocess, 425.3ms inference, 4.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 414.9ms\n",
      "Speed: 6.4ms preprocess, 414.9ms inference, 4.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 18 persons, 16 cars, 25 motorcycles, 1 bus, 3 trucks, 1 traffic light, 411.2ms\n",
      "Speed: 7.7ms preprocess, 411.2ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 2 persons, 25 cars, 3 motorcycles, 1 truck, 414.3ms\n",
      "Speed: 4.7ms preprocess, 414.3ms inference, 4.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 27 persons, 28 cars, 1 bus, 6 trucks, 408.9ms\n",
      "Speed: 6.2ms preprocess, 408.9ms inference, 4.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 30 persons, 28 cars, 7 motorcycles, 417.7ms\n",
      "Speed: 6.4ms preprocess, 417.7ms inference, 5.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 17 persons, 18 cars, 24 motorcycles, 2 buss, 2 trucks, 1 traffic light, 413.8ms\n",
      "Speed: 6.9ms preprocess, 413.8ms inference, 3.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 2 persons, 23 cars, 2 motorcycles, 1 truck, 407.6ms\n",
      "Speed: 4.7ms preprocess, 407.6ms inference, 5.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 29 persons, 33 cars, 1 bus, 7 trucks, 415.2ms\n",
      "Speed: 7.7ms preprocess, 415.2ms inference, 4.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 407.0ms\n",
      "Speed: 5.8ms preprocess, 407.0ms inference, 4.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 409.5ms\n",
      "Speed: 7.5ms preprocess, 409.5ms inference, 3.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 person, 24 cars, 1 bus, 1 truck, 413.5ms\n",
      "Speed: 5.6ms preprocess, 413.5ms inference, 3.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 429.7ms\n",
      "Speed: 6.3ms preprocess, 429.7ms inference, 3.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 person, 413.3ms\n",
      "Speed: 5.3ms preprocess, 413.3ms inference, 4.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 21 persons, 15 cars, 21 motorcycles, 2 buss, 1 truck, 3 traffic lights, 412.9ms\n",
      "Speed: 6.2ms preprocess, 412.9ms inference, 4.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 445.4ms\n",
      "Speed: 10.4ms preprocess, 445.4ms inference, 3.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 24 persons, 31 cars, 3 motorcycles, 1 bus, 8 trucks, 417.9ms\n",
      "Speed: 6.0ms preprocess, 417.9ms inference, 4.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 29 persons, 1 bicycle, 28 cars, 6 motorcycles, 411.5ms\n",
      "Speed: 6.4ms preprocess, 411.5ms inference, 5.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 22 persons, 15 cars, 24 motorcycles, 2 buss, 1 truck, 3 traffic lights, 412.6ms\n",
      "Speed: 5.5ms preprocess, 412.6ms inference, 4.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 25 cars, 2 motorcycles, 1 bus, 1 truck, 419.1ms\n",
      "Speed: 4.9ms preprocess, 419.1ms inference, 5.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 27 persons, 30 cars, 1 motorcycle, 1 bus, 7 trucks, 420.0ms\n",
      "Speed: 6.4ms preprocess, 420.0ms inference, 4.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 420.1ms\n",
      "Speed: 6.6ms preprocess, 420.1ms inference, 4.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 398.2ms\n",
      "Speed: 8.1ms preprocess, 398.2ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 24 cars, 1 motorcycle, 1 truck, 549.4ms\n",
      "Speed: 5.6ms preprocess, 549.4ms inference, 4.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 24 persons, 27 cars, 1 motorcycle, 1 bus, 9 trucks, 409.4ms\n",
      "Speed: 5.7ms preprocess, 409.4ms inference, 4.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 2 cars, 440.9ms\n",
      "Speed: 6.5ms preprocess, 440.9ms inference, 3.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 420.6ms\n",
      "Speed: 5.7ms preprocess, 420.6ms inference, 4.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 person, 22 cars, 1 motorcycle, 1 bus, 1 truck, 417.5ms\n",
      "Speed: 6.3ms preprocess, 417.5ms inference, 3.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 24 persons, 26 cars, 1 motorcycle, 1 bus, 10 trucks, 438.7ms\n",
      "Speed: 7.1ms preprocess, 438.7ms inference, 5.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 406.9ms\n",
      "Speed: 5.1ms preprocess, 406.9ms inference, 5.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 17 persons, 16 cars, 19 motorcycles, 1 bus, 2 trucks, 3 traffic lights, 408.6ms\n",
      "Speed: 5.7ms preprocess, 408.6ms inference, 3.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 person, 26 cars, 2 motorcycles, 1 bus, 1 truck, 409.7ms\n",
      "Speed: 6.5ms preprocess, 409.7ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 24 persons, 28 cars, 3 motorcycles, 2 buss, 9 trucks, 419.2ms\n",
      "Speed: 6.5ms preprocess, 419.2ms inference, 4.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 415.7ms\n",
      "Speed: 6.2ms preprocess, 415.7ms inference, 5.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 410.1ms\n",
      "Speed: 7.7ms preprocess, 410.1ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 24 cars, 2 motorcycles, 1 truck, 436.7ms\n",
      "Speed: 5.5ms preprocess, 436.7ms inference, 4.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 24 persons, 31 cars, 2 motorcycles, 1 bus, 7 trucks, 411.6ms\n",
      "Speed: 8.1ms preprocess, 411.6ms inference, 4.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 414.5ms\n",
      "Speed: 6.5ms preprocess, 414.5ms inference, 4.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 405.5ms\n",
      "Speed: 7.2ms preprocess, 405.5ms inference, 4.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 4 persons, 22 cars, 3 motorcycles, 1 bus, 1 truck, 407.9ms\n",
      "Speed: 7.0ms preprocess, 407.9ms inference, 3.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 21 persons, 30 cars, 1 motorcycle, 1 bus, 6 trucks, 432.5ms\n",
      "Speed: 8.1ms preprocess, 432.5ms inference, 5.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 421.6ms\n",
      "Speed: 4.7ms preprocess, 421.6ms inference, 5.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 18 persons, 18 cars, 18 motorcycles, 1 bus, 1 truck, 3 traffic lights, 419.0ms\n",
      "Speed: 6.0ms preprocess, 419.0ms inference, 4.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 2 persons, 24 cars, 3 motorcycles, 1 bus, 1 truck, 408.9ms\n",
      "Speed: 5.7ms preprocess, 408.9ms inference, 4.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 431.5ms\n",
      "Speed: 6.2ms preprocess, 431.5ms inference, 3.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 person, 421.1ms\n",
      "Speed: 5.6ms preprocess, 421.1ms inference, 5.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 405.0ms\n",
      "Speed: 7.4ms preprocess, 405.0ms inference, 5.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 26 cars, 1 motorcycle, 1 truck, 414.8ms\n",
      "Speed: 6.2ms preprocess, 414.8ms inference, 4.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 25 persons, 32 cars, 2 motorcycles, 1 bus, 8 trucks, 427.6ms\n",
      "Speed: 6.2ms preprocess, 427.6ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 415.9ms\n",
      "Speed: 6.3ms preprocess, 415.9ms inference, 4.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 410.3ms\n",
      "Speed: 5.8ms preprocess, 410.3ms inference, 3.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 25 cars, 1 truck, 411.5ms\n",
      "Speed: 6.3ms preprocess, 411.5ms inference, 4.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 25 persons, 32 cars, 3 motorcycles, 1 bus, 6 trucks, 425.9ms\n",
      "Speed: 6.3ms preprocess, 425.9ms inference, 4.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 18 persons, 1 bicycle, 31 cars, 10 motorcycles, 414.1ms\n",
      "Speed: 4.7ms preprocess, 414.1ms inference, 4.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 16 persons, 13 cars, 22 motorcycles, 2 buss, 2 trucks, 1 traffic light, 416.8ms\n",
      "Speed: 6.3ms preprocess, 416.8ms inference, 4.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 27 cars, 1 bus, 1 truck, 416.6ms\n",
      "Speed: 5.5ms preprocess, 416.6ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 23 persons, 33 cars, 3 motorcycles, 1 bus, 7 trucks, 400.5ms\n",
      "Speed: 7.4ms preprocess, 400.5ms inference, 4.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 409.8ms\n",
      "Speed: 6.6ms preprocess, 409.8ms inference, 3.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 410.5ms\n",
      "Speed: 7.3ms preprocess, 410.5ms inference, 5.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 24 cars, 1 motorcycle, 1 bus, 1 truck, 418.5ms\n",
      "Speed: 6.4ms preprocess, 418.5ms inference, 4.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 23 persons, 32 cars, 3 motorcycles, 1 bus, 6 trucks, 428.1ms\n",
      "Speed: 6.3ms preprocess, 428.1ms inference, 3.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 2 cars, 415.9ms\n",
      "Speed: 20.9ms preprocess, 415.9ms inference, 3.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 17 persons, 14 cars, 22 motorcycles, 2 buss, 1 truck, 421.0ms\n",
      "Speed: 7.0ms preprocess, 421.0ms inference, 8.5ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO  # Your YOLO model\n",
    "from collections import defaultdict\n",
    "\n",
    "model = YOLO('yolo12n.pt')  # Load your model\n",
    "# tracker = YourTrackerClass()  # Your object tracker\n",
    "# class_list = model.names  # Class names from YOLO model\n",
    "\n",
    "# Load videos\n",
    "caps = [\n",
    "    cv2.VideoCapture('traffic1.mp4'),\n",
    "    cv2.VideoCapture('traffic2.mp4'),\n",
    "    cv2.VideoCapture('traffic3.mp4'),\n",
    "    cv2.VideoCapture('traffic4.mp4')\n",
    "]\n",
    "\n",
    "counter = [0, 0, 0, 0]  # Vehicle counters for each video\n",
    "tracked_ids = [set(), set(), set(), set()]  # Unique IDs for each video\n",
    "\n",
    "while True:\n",
    "    frames = []\n",
    "\n",
    "    for idx, cap in enumerate(caps):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            frame = cv2.imread('black.jpg')\n",
    "            frame = cv2.resize(frame, (540, 360))\n",
    "            frames.append(frame)\n",
    "            continue\n",
    "\n",
    "        frame = cv2.resize(frame, (540, 360))\n",
    "\n",
    "        results = model.track(frame, persist=True)\n",
    "        boxes = results[0].boxes.data.cpu().numpy()\n",
    "        df = pd.DataFrame(boxes).astype('float')\n",
    "\n",
    "        detections = []\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            x1, y1, x2, y2, score, class_id = row[:6]\n",
    "            x1, y1, x2, y2, class_id = map(int, [x1, y1, x2, y2, class_id])\n",
    "            label = class_list[class_id]\n",
    "\n",
    "            # Filter Vehicles Only (Optional)\n",
    "            if label in class_list:\n",
    "                # detections.append([x1, y1, x2, y2])\n",
    "                detections.append([x1, y1, x2 - x1, y2 - y1])\n",
    "\n",
    "                # Draw Bounding Box with Class Name\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 255), 2)\n",
    "                cv2.putText(frame, f'{label}', (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "\n",
    "        bbox_id = tracker.update(detections)\n",
    "        frame_height = frame.shape[0]\n",
    "\n",
    "        if detections:  # If vehicles are detected\n",
    "            min_y = min([y for (_, y, _, _) in detections])\n",
    "            distance = frame_height - min_y\n",
    "        else:\n",
    "            distance = 0  # No vehicles detected\n",
    "\n",
    "        cv2.putText(frame, f'Distance to Farthest: {distance}px', (10, 90), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "        # for bbox in bbox_id:\n",
    "        #     x3, y3, x4, y4, id = bbox\n",
    "        #     cv2.putText(frame, f'ID: {id}', (x3, y4 + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "        #     if id not in tracked_ids[idx]:\n",
    "        #         tracked_ids[idx].add(id)\n",
    "        #         counter[idx] += 1\n",
    "\n",
    "        # Show vehicle count on top-left\n",
    "        cv2.putText(frame, f'Count: {counter[idx]}', (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        frames.append(frame)\n",
    "\n",
    "    # Merge frames into 2x2 grid\n",
    "    top_row = cv2.hconcat([frames[0], frames[1]])\n",
    "    bottom_row = cv2.hconcat([frames[2], frames[3]])\n",
    "    final_output = cv2.vconcat([top_row, bottom_row])\n",
    "\n",
    "    cv2.imshow(\"Smart Traffic Monitoring - Multi View\", final_output)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "for cap in caps:\n",
    "    cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba8889c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def draw_signal(img, x, y, active_color):\n",
    "    # Draw signal body\n",
    "    cv2.rectangle(img, (x, y), (x+50, y+150), (50, 50, 50), -1)\n",
    "\n",
    "    colors = [(0,0,255), (0,255,255), (0,255,0)]  # Red, Yellow, Green\n",
    "\n",
    "    for i, color in enumerate(colors):\n",
    "        center = (x+25, y+25 + i*50)\n",
    "        fill = color if i == active_color else (30, 30, 30)\n",
    "        cv2.circle(img, center, 15, fill, -1)\n",
    "\n",
    "frame = np.zeros((500, 500, 3), dtype=np.uint8)\n",
    "\n",
    "# Draw 4 signals (simulate changing signal using active_color)\n",
    "draw_signal(frame, 100, 100, 0)  # Top-Left -> Red ON\n",
    "draw_signal(frame, 350, 100, 1)  # Top-Right -> Yellow ON\n",
    "draw_signal(frame, 100, 350, 2)  # Bottom-Left -> Green ON\n",
    "draw_signal(frame, 350, 350, 0)  # Bottom-Right -> Red ON\n",
    "\n",
    "cv2.imshow(\"Traffic Signals\", frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85a34765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 18 cars, 1 truck, 449.7ms\n",
      "Speed: 7.3ms preprocess, 449.7ms inference, 4.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 25 persons, 33 cars, 1 motorcycle, 1 bus, 13 trucks, 488.2ms\n",
      "Speed: 6.3ms preprocess, 488.2ms inference, 5.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 25 persons, 19 cars, 4 motorcycles, 544.0ms\n",
      "Speed: 6.1ms preprocess, 544.0ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 495.6ms\n",
      "Speed: 11.9ms preprocess, 495.6ms inference, 6.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 23 cars, 1 motorcycle, 2 trucks, 719.9ms\n",
      "Speed: 14.4ms preprocess, 719.9ms inference, 3.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 26 persons, 29 cars, 1 motorcycle, 2 buss, 12 trucks, 449.3ms\n",
      "Speed: 6.3ms preprocess, 449.3ms inference, 4.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 21 persons, 2 bicycles, 22 cars, 6 motorcycles, 467.3ms\n",
      "Speed: 6.5ms preprocess, 467.3ms inference, 5.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 motorcycle, 450.9ms\n",
      "Speed: 8.1ms preprocess, 450.9ms inference, 5.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 23 cars, 1 motorcycle, 1 bus, 2 trucks, 452.5ms\n",
      "Speed: 7.6ms preprocess, 452.5ms inference, 4.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 25 persons, 28 cars, 1 motorcycle, 2 buss, 10 trucks, 452.0ms\n",
      "Speed: 6.9ms preprocess, 452.0ms inference, 4.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 2 cars, 462.0ms\n",
      "Speed: 9.1ms preprocess, 462.0ms inference, 6.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 truck, 436.5ms\n",
      "Speed: 4.3ms preprocess, 436.5ms inference, 6.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 23 cars, 1 motorcycle, 1 truck, 435.9ms\n",
      "Speed: 6.3ms preprocess, 435.9ms inference, 5.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 454.3ms\n",
      "Speed: 9.3ms preprocess, 454.3ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 434.9ms\n",
      "Speed: 7.9ms preprocess, 434.9ms inference, 4.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 1 motorcycle, 453.3ms\n",
      "Speed: 8.9ms preprocess, 453.3ms inference, 4.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 24 cars, 1 motorcycle, 1 truck, 451.3ms\n",
      "Speed: 8.3ms preprocess, 451.3ms inference, 4.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 446.9ms\n",
      "Speed: 6.9ms preprocess, 446.9ms inference, 6.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 31 persons, 24 cars, 6 motorcycles, 441.8ms\n",
      "Speed: 8.8ms preprocess, 441.8ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 23 persons, 16 cars, 24 motorcycles, 3 trucks, 433.5ms\n",
      "Speed: 9.4ms preprocess, 433.5ms inference, 3.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 22 cars, 1 motorcycle, 4 trucks, 434.0ms\n",
      "Speed: 6.2ms preprocess, 434.0ms inference, 3.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 25 persons, 30 cars, 4 motorcycles, 2 buss, 11 trucks, 441.3ms\n",
      "Speed: 5.2ms preprocess, 441.3ms inference, 4.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 24 persons, 26 cars, 4 motorcycles, 429.6ms\n",
      "Speed: 6.5ms preprocess, 429.6ms inference, 5.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 23 persons, 16 cars, 23 motorcycles, 3 trucks, 432.3ms\n",
      "Speed: 9.4ms preprocess, 432.3ms inference, 5.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 25 cars, 1 motorcycle, 2 buss, 2 trucks, 428.6ms\n",
      "Speed: 5.1ms preprocess, 428.6ms inference, 4.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 24 persons, 28 cars, 2 motorcycles, 2 buss, 11 trucks, 453.6ms\n",
      "Speed: 5.4ms preprocess, 453.6ms inference, 5.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 430.7ms\n",
      "Speed: 9.6ms preprocess, 430.7ms inference, 4.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 21 persons, 16 cars, 23 motorcycles, 3 trucks, 430.1ms\n",
      "Speed: 9.4ms preprocess, 430.1ms inference, 5.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 24 cars, 1 motorcycle, 1 bus, 1 truck, 439.1ms\n",
      "Speed: 4.8ms preprocess, 439.1ms inference, 4.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 436.6ms\n",
      "Speed: 8.1ms preprocess, 436.6ms inference, 4.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 426.0ms\n",
      "Speed: 6.4ms preprocess, 426.0ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 434.9ms\n",
      "Speed: 5.8ms preprocess, 434.9ms inference, 3.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 24 cars, 1 motorcycle, 2 buss, 440.7ms\n",
      "Speed: 6.4ms preprocess, 440.7ms inference, 4.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 25 persons, 24 cars, 1 motorcycle, 2 buss, 12 trucks, 464.1ms\n",
      "Speed: 6.2ms preprocess, 464.1ms inference, 5.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 2 cars, 448.4ms\n",
      "Speed: 10.0ms preprocess, 448.4ms inference, 3.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 20 persons, 16 cars, 23 motorcycles, 3 trucks, 428.4ms\n",
      "Speed: 6.0ms preprocess, 428.4ms inference, 4.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 435.3ms\n",
      "Speed: 4.7ms preprocess, 435.3ms inference, 4.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 24 persons, 25 cars, 2 motorcycles, 1 bus, 14 trucks, 452.2ms\n",
      "Speed: 6.1ms preprocess, 452.2ms inference, 4.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 27 persons, 25 cars, 10 motorcycles, 443.5ms\n",
      "Speed: 5.9ms preprocess, 443.5ms inference, 4.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 19 persons, 16 cars, 21 motorcycles, 3 trucks, 433.0ms\n",
      "Speed: 6.3ms preprocess, 433.0ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 21 cars, 1 motorcycle, 2 buss, 1 truck, 447.1ms\n",
      "Speed: 6.9ms preprocess, 447.1ms inference, 5.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 21 persons, 29 cars, 4 motorcycles, 1 bus, 13 trucks, 442.9ms\n",
      "Speed: 5.6ms preprocess, 442.9ms inference, 4.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 25 persons, 26 cars, 8 motorcycles, 421.0ms\n",
      "Speed: 7.9ms preprocess, 421.0ms inference, 3.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 19 persons, 16 cars, 22 motorcycles, 3 trucks, 420.5ms\n",
      "Speed: 8.5ms preprocess, 420.5ms inference, 3.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 25 cars, 1 motorcycle, 1 bus, 2 trucks, 426.3ms\n",
      "Speed: 4.6ms preprocess, 426.3ms inference, 3.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 20 persons, 28 cars, 3 motorcycles, 1 bus, 13 trucks, 437.7ms\n",
      "Speed: 9.0ms preprocess, 437.7ms inference, 6.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 25 persons, 1 bicycle, 25 cars, 10 motorcycles, 432.7ms\n",
      "Speed: 7.6ms preprocess, 432.7ms inference, 4.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 21 persons, 16 cars, 25 motorcycles, 3 trucks, 446.2ms\n",
      "Speed: 7.4ms preprocess, 446.2ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 28 cars, 1 motorcycle, 2 trucks, 424.3ms\n",
      "Speed: 6.1ms preprocess, 424.3ms inference, 4.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 21 persons, 27 cars, 3 motorcycles, 1 bus, 15 trucks, 442.8ms\n",
      "Speed: 6.5ms preprocess, 442.8ms inference, 4.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 440.8ms\n",
      "Speed: 6.1ms preprocess, 440.8ms inference, 4.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 21 persons, 16 cars, 23 motorcycles, 1 bus, 3 trucks, 429.9ms\n",
      "Speed: 8.3ms preprocess, 429.9ms inference, 3.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 24 cars, 2 motorcycles, 3 trucks, 424.5ms\n",
      "Speed: 5.2ms preprocess, 424.5ms inference, 3.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 23 persons, 32 cars, 3 motorcycles, 1 bus, 10 trucks, 441.1ms\n",
      "Speed: 6.0ms preprocess, 441.1ms inference, 4.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 person, 1 car, 416.1ms\n",
      "Speed: 8.1ms preprocess, 416.1ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 20 persons, 16 cars, 24 motorcycles, 1 bus, 3 trucks, 433.0ms\n",
      "Speed: 5.4ms preprocess, 433.0ms inference, 4.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 421.4ms\n",
      "Speed: 5.4ms preprocess, 421.4ms inference, 4.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 23 persons, 28 cars, 2 motorcycles, 1 bus, 8 trucks, 441.2ms\n",
      "Speed: 6.1ms preprocess, 441.2ms inference, 4.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 464.8ms\n",
      "Speed: 6.2ms preprocess, 464.8ms inference, 4.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 19 persons, 16 cars, 22 motorcycles, 1 bus, 3 trucks, 448.5ms\n",
      "Speed: 8.0ms preprocess, 448.5ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 26 cars, 1 motorcycle, 3 trucks, 449.8ms\n",
      "Speed: 4.9ms preprocess, 449.8ms inference, 4.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 26 persons, 31 cars, 5 motorcycles, 1 bus, 10 trucks, 457.3ms\n",
      "Speed: 31.9ms preprocess, 457.3ms inference, 4.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 428.9ms\n",
      "Speed: 5.8ms preprocess, 428.9ms inference, 5.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 19 persons, 16 cars, 20 motorcycles, 1 bus, 3 trucks, 424.7ms\n",
      "Speed: 6.4ms preprocess, 424.7ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 26 cars, 3 motorcycles, 1 bus, 3 trucks, 448.2ms\n",
      "Speed: 5.5ms preprocess, 448.2ms inference, 3.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 27 persons, 30 cars, 5 motorcycles, 1 bus, 11 trucks, 452.8ms\n",
      "Speed: 6.8ms preprocess, 452.8ms inference, 6.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 26 persons, 25 cars, 7 motorcycles, 461.9ms\n",
      "Speed: 6.4ms preprocess, 461.9ms inference, 4.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 18 persons, 16 cars, 22 motorcycles, 1 bus, 3 trucks, 412.4ms\n",
      "Speed: 8.9ms preprocess, 412.4ms inference, 4.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 25 cars, 2 motorcycles, 1 bus, 2 trucks, 421.0ms\n",
      "Speed: 4.9ms preprocess, 421.0ms inference, 4.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 22 persons, 28 cars, 5 motorcycles, 1 bus, 13 trucks, 446.2ms\n",
      "Speed: 7.4ms preprocess, 446.2ms inference, 6.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 421.9ms\n",
      "Speed: 8.1ms preprocess, 421.9ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 20 persons, 16 cars, 21 motorcycles, 1 bus, 3 trucks, 416.9ms\n",
      "Speed: 6.3ms preprocess, 416.9ms inference, 5.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 26 cars, 2 motorcycles, 2 trucks, 433.8ms\n",
      "Speed: 5.3ms preprocess, 433.8ms inference, 5.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 24 persons, 26 cars, 2 motorcycles, 2 buss, 12 trucks, 431.2ms\n",
      "Speed: 6.5ms preprocess, 431.2ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 23 persons, 26 cars, 5 motorcycles, 448.9ms\n",
      "Speed: 7.0ms preprocess, 448.9ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 19 persons, 16 cars, 24 motorcycles, 3 trucks, 416.3ms\n",
      "Speed: 8.0ms preprocess, 416.3ms inference, 5.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 23 cars, 1 motorcycle, 1 bus, 2 trucks, 421.4ms\n",
      "Speed: 5.9ms preprocess, 421.4ms inference, 4.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 21 persons, 32 cars, 5 motorcycles, 1 bus, 10 trucks, 438.1ms\n",
      "Speed: 5.4ms preprocess, 438.1ms inference, 4.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 2 cars, 427.2ms\n",
      "Speed: 7.1ms preprocess, 427.2ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 20 persons, 17 cars, 22 motorcycles, 3 trucks, 440.6ms\n",
      "Speed: 6.2ms preprocess, 440.6ms inference, 5.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 21 cars, 3 motorcycles, 1 bus, 1 truck, 428.0ms\n",
      "Speed: 5.6ms preprocess, 428.0ms inference, 4.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 21 persons, 28 cars, 4 motorcycles, 2 buss, 11 trucks, 460.2ms\n",
      "Speed: 5.8ms preprocess, 460.2ms inference, 4.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 26 persons, 22 cars, 7 motorcycles, 422.6ms\n",
      "Speed: 6.9ms preprocess, 422.6ms inference, 4.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 22 persons, 16 cars, 23 motorcycles, 3 trucks, 436.3ms\n",
      "Speed: 6.0ms preprocess, 436.3ms inference, 5.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 23 cars, 3 motorcycles, 1 bus, 1 truck, 434.5ms\n",
      "Speed: 6.4ms preprocess, 434.5ms inference, 4.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 24 persons, 27 cars, 3 motorcycles, 2 buss, 12 trucks, 460.5ms\n",
      "Speed: 7.0ms preprocess, 460.5ms inference, 5.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 432.4ms\n",
      "Speed: 6.7ms preprocess, 432.4ms inference, 6.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 20 persons, 16 cars, 22 motorcycles, 2 trucks, 423.2ms\n",
      "Speed: 5.5ms preprocess, 423.2ms inference, 5.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 24 cars, 2 motorcycles, 1 bus, 1 truck, 453.0ms\n",
      "Speed: 6.6ms preprocess, 453.0ms inference, 4.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 23 persons, 27 cars, 2 motorcycles, 1 bus, 10 trucks, 438.7ms\n",
      "Speed: 6.5ms preprocess, 438.7ms inference, 5.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 814.4ms\n",
      "Speed: 7.8ms preprocess, 814.4ms inference, 5.7ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 22 persons, 16 cars, 25 motorcycles, 2 trucks, 457.7ms\n",
      "Speed: 7.3ms preprocess, 457.7ms inference, 4.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 23 cars, 2 motorcycles, 2 buss, 1 truck, 570.6ms\n",
      "Speed: 6.2ms preprocess, 570.6ms inference, 4.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 26 persons, 33 cars, 3 motorcycles, 1 bus, 9 trucks, 431.0ms\n",
      "Speed: 7.4ms preprocess, 431.0ms inference, 5.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 3 cars, 496.3ms\n",
      "Speed: 7.2ms preprocess, 496.3ms inference, 5.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 23 persons, 15 cars, 23 motorcycles, 2 trucks, 610.2ms\n",
      "Speed: 11.6ms preprocess, 610.2ms inference, 6.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 460.0ms\n",
      "Speed: 4.6ms preprocess, 460.0ms inference, 5.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 22 persons, 32 cars, 4 motorcycles, 1 bus, 13 trucks, 514.3ms\n",
      "Speed: 9.3ms preprocess, 514.3ms inference, 6.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 440.7ms\n",
      "Speed: 10.0ms preprocess, 440.7ms inference, 4.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 20 persons, 15 cars, 25 motorcycles, 2 trucks, 452.5ms\n",
      "Speed: 7.9ms preprocess, 452.5ms inference, 5.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 25 cars, 1 bus, 1 truck, 461.3ms\n",
      "Speed: 4.9ms preprocess, 461.3ms inference, 4.1ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 23 persons, 33 cars, 3 motorcycles, 2 buss, 9 trucks, 443.8ms\n",
      "Speed: 8.3ms preprocess, 443.8ms inference, 5.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 444.2ms\n",
      "Speed: 7.7ms preprocess, 444.2ms inference, 5.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 19 persons, 15 cars, 29 motorcycles, 2 trucks, 440.4ms\n",
      "Speed: 7.2ms preprocess, 440.4ms inference, 5.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 471.3ms\n",
      "Speed: 4.6ms preprocess, 471.3ms inference, 6.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 25 persons, 30 cars, 2 motorcycles, 3 buss, 9 trucks, 637.1ms\n",
      "Speed: 7.1ms preprocess, 637.1ms inference, 4.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 504.9ms\n",
      "Speed: 8.4ms preprocess, 504.9ms inference, 4.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 19 persons, 16 cars, 27 motorcycles, 2 trucks, 520.1ms\n",
      "Speed: 7.3ms preprocess, 520.1ms inference, 9.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 490.0ms\n",
      "Speed: 20.3ms preprocess, 490.0ms inference, 4.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 28 persons, 27 cars, 3 motorcycles, 2 buss, 8 trucks, 435.5ms\n",
      "Speed: 6.1ms preprocess, 435.5ms inference, 4.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 2 cars, 448.5ms\n",
      "Speed: 5.4ms preprocess, 448.5ms inference, 4.6ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 20 persons, 17 cars, 22 motorcycles, 1 bus, 2 trucks, 434.8ms\n",
      "Speed: 7.5ms preprocess, 434.8ms inference, 4.3ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tracker import Tracker\n",
    "from ultralytics import YOLO\n",
    "from itertools import cycle\n",
    "import time\n",
    "\n",
    "model = YOLO('yolo12n.pt')\n",
    "tracker = Tracker()\n",
    "\n",
    "caps = [cv2.VideoCapture(f'traffic{i}.mp4') for i in range(1, 5)]\n",
    "signal_states = ['RED', 'RED', 'RED', 'RED']\n",
    "signal_timer = [0, 0, 0, 0]\n",
    "tracked_ids = [set() for _ in range(4)]\n",
    "\n",
    "frame_w, frame_h = 540, 360\n",
    "signal_order = cycle([0, 1, 2, 3])  # Frame 1 → 2 → 3 → 4 → repeat\n",
    "current_signal = next(signal_order)\n",
    "green_end_time = 0\n",
    "yellow_time = 5\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "def get_max_distance(frame, detections):\n",
    "    max_dist = 0\n",
    "    for det in detections:\n",
    "        _, y, _, h = det\n",
    "        dist = frame_h - (y + h)\n",
    "        max_dist = max(max_dist, dist)\n",
    "    return max_dist\n",
    "\n",
    "def draw_signal(state, timer):\n",
    "    signal = np.zeros((150, 100, 3), dtype=np.uint8) + 50\n",
    "    colors = {'RED': (0, 0, 255), 'YELLOW': (0, 255, 255), 'GREEN': (0, 255, 0)}\n",
    "    positions = [(50, 30), (50, 75), (50, 120)]\n",
    "    labels = ['RED', 'YELLOW', 'GREEN']\n",
    "\n",
    "    for idx, pos in enumerate(positions):\n",
    "        col = (50, 50, 50)\n",
    "        if state == labels[idx]:\n",
    "            col = colors[state]\n",
    "        cv2.circle(signal, pos, 15, col, -1)\n",
    "\n",
    "    cv2.putText(signal, f'{timer}s', (20, 140), font, 0.6, (255, 255, 255), 2)\n",
    "    return signal\n",
    "\n",
    "while True:\n",
    "    frames, detections_per_frame = [], []\n",
    "\n",
    "    # Read and Detect Vehicles\n",
    "    for idx, cap in enumerate(caps):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            frame = cv2.imread('black.jpg')\n",
    "        frame = cv2.resize(frame, (frame_w, frame_h))\n",
    "\n",
    "        detections = []\n",
    "        if idx != current_signal or signal_states[idx] != 'GREEN':\n",
    "            results = model.track(frame, persist=True)\n",
    "            boxes = results[0].boxes.data.cpu().numpy()\n",
    "            df = pd.DataFrame(boxes).astype('float')\n",
    "\n",
    "            for _, row in df.iterrows():\n",
    "                x1, y1, x2, y2, _, _ = map(int, row[:6])\n",
    "                detections.append([x1, y1, x2 - x1, y2 - y1])\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 255), 2)\n",
    "\n",
    "        frames.append(frame)\n",
    "        detections_per_frame.append(detections)\n",
    "\n",
    "    # Signal Timing Logic\n",
    "    if time.time() >= green_end_time:\n",
    "        if signal_states[current_signal] == 'GREEN':\n",
    "            signal_states[current_signal] = 'YELLOW'\n",
    "            green_end_time = time.time() + yellow_time\n",
    "        elif signal_states[current_signal] == 'YELLOW':\n",
    "            signal_states[current_signal] = 'RED'\n",
    "            current_signal = next(signal_order)\n",
    "\n",
    "            max_dist = get_max_distance(frames[current_signal], detections_per_frame[current_signal])\n",
    "            if max_dist > 250:\n",
    "                green_time = 60\n",
    "            else:\n",
    "                green_time = max(6, (max_dist // 25) * 6)\n",
    "\n",
    "            signal_states[current_signal] = 'GREEN'\n",
    "            green_end_time = time.time() + green_time\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    # Update Timer for All Signals\n",
    "    for idx in range(4):\n",
    "        remain = int(green_end_time - time.time()) if idx == current_signal else 0\n",
    "        signal_timer[idx] = max(0, remain)\n",
    "\n",
    "    # Update Tracker\n",
    "    for idx, frame in enumerate(frames):\n",
    "        bbox_id = tracker.update(detections_per_frame[idx])\n",
    "        for bbox in bbox_id:\n",
    "            x, y, w, h, id = bbox\n",
    "            cv2.putText(frame, str(id), (x, y - 10), font, 0.6, (0, 255, 255), 2)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Create Signals Frame\n",
    "    signal_frames = [draw_signal(signal_states[idx], signal_timer[idx]) for idx in range(4)]\n",
    "    top_signals = np.hstack((signal_frames[0], signal_frames[1]))\n",
    "    bottom_signals = np.hstack((signal_frames[2], signal_frames[3]))\n",
    "    signals_frame = np.vstack((top_signals, bottom_signals))\n",
    "\n",
    "    # Merge All Video Frames\n",
    "    top_row = np.hstack((frames[0], frames[1]))\n",
    "    bottom_row = np.hstack((frames[2], frames[3]))\n",
    "    combined_frame = np.vstack((top_row, bottom_row))\n",
    "\n",
    "    # Final Display\n",
    "    # final_display = np.hstack((combined_frame, cv2.resize(signals_frame, (200, 300))))\n",
    "    final_display = np.hstack((combined_frame, cv2.resize(signals_frame, (200, combined_frame.shape[0]))))\n",
    "\n",
    "\n",
    "    cv2.imshow(\"Traffic Management System\", final_display)\n",
    "\n",
    "    if cv2.waitKey(1) == 27:  # ESC to Exit\n",
    "        break\n",
    "\n",
    "for cap in caps:\n",
    "    cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d04af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 448x640 18 cars, 1 truck, 492.8ms\n",
      "Speed: 8.4ms preprocess, 492.8ms inference, 4.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 25 persons, 33 cars, 1 motorcycle, 1 bus, 13 trucks, 539.8ms\n",
      "Speed: 5.5ms preprocess, 539.8ms inference, 7.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 25 persons, 19 cars, 4 motorcycles, 452.0ms\n",
      "Speed: 8.3ms preprocess, 452.0ms inference, 3.9ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 car, 455.9ms\n",
      "Speed: 5.7ms preprocess, 455.9ms inference, 6.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 23 cars, 1 motorcycle, 2 trucks, 575.5ms\n",
      "Speed: 27.7ms preprocess, 575.5ms inference, 6.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 26 persons, 29 cars, 1 motorcycle, 2 buss, 12 trucks, 457.2ms\n",
      "Speed: 16.2ms preprocess, 457.2ms inference, 4.8ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 21 persons, 2 bicycles, 22 cars, 6 motorcycles, 438.0ms\n",
      "Speed: 6.6ms preprocess, 438.0ms inference, 6.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 448x640 1 motorcycle, 440.7ms\n",
      "Speed: 6.5ms preprocess, 440.7ms inference, 4.6ms postprocess per image at shape (1, 3, 448, 640)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "170",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 50\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m df.iterrows():\n\u001b[32m     49\u001b[39m     x1, y1, x2, y2, class_id, score = \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mint\u001b[39m, row[:\u001b[32m6\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     label = \u001b[43mclass_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclass_id\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mcar\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtruck\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mbus\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmotorbike\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m     52\u001b[39m         detections.append([x1, y1, x2 - x1, y2 - y1])\n",
      "\u001b[31mKeyError\u001b[39m: 170"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "from tracker import Tracker\n",
    "\n",
    "model = YOLO('yolo12n.pt')\n",
    "tracker = Tracker()\n",
    "\n",
    "caps = [cv2.VideoCapture(f'traffic{i}.mp4') for i in range(1, 5)]\n",
    "class_list = model.names\n",
    "\n",
    "frame_width, frame_height = 540, 360\n",
    "\n",
    "signal_states = ['RED', 'RED', 'RED', 'RED']  \n",
    "signal_timers = [0, 0, 0, 0]  \n",
    "signal_durations = [0, 0, 0, 0]  \n",
    "\n",
    "signal_rotation_index = 0  \n",
    "yellow_duration = 5\n",
    "green_active = False\n",
    "green_start_time = 0\n",
    "prev_time = time.time()\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "colors = {'RED': (0, 0, 255), 'YELLOW': (0, 255, 255), 'GREEN': (0, 255, 0)}\n",
    "\n",
    "while True:\n",
    "    frames = []\n",
    "    max_distances = []\n",
    "\n",
    "    # Read all videos\n",
    "    for idx, cap in enumerate(caps):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            frame = cv2.imread('black.jpg')\n",
    "        frame = cv2.resize(frame, (frame_width, frame_height))\n",
    "\n",
    "        results = model.track(frame, persist=True)\n",
    "        boxes = results[0].boxes.data.cpu().numpy() if results[0].boxes else []\n",
    "        df = pd.DataFrame(boxes).astype('float')\n",
    "\n",
    "        detections = []\n",
    "        max_dist = 0\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            x1, y1, x2, y2, class_id, score = map(int, row[:6])\n",
    "            label = class_list[class_id]\n",
    "            if label in ['car', 'truck', 'bus', 'motorbike']:\n",
    "                detections.append([x1, y1, x2 - x1, y2 - y1])\n",
    "                distance = frame_height - y2\n",
    "                if distance > max_dist:\n",
    "                    max_dist = distance\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 255), 2)\n",
    "\n",
    "        max_distances.append(max_dist)\n",
    "        frames.append(frame)\n",
    "\n",
    "    # Signal Logic\n",
    "    current_time = time.time()\n",
    "    elapsed = current_time - prev_time\n",
    "\n",
    "    if elapsed >= 1:\n",
    "        prev_time = current_time\n",
    "        # Countdown timers\n",
    "        for idx in range(4):\n",
    "            if signal_timers[idx] > 0:\n",
    "                signal_timers[idx] -= 1\n",
    "        \n",
    "        # Change signals when timer finishes\n",
    "        if signal_timers[signal_rotation_index] <= 0:\n",
    "            signal_states[signal_rotation_index] = 'YELLOW' if signal_states[signal_rotation_index] == 'GREEN' else 'RED'\n",
    "            \n",
    "            if signal_states[signal_rotation_index] == 'RED':\n",
    "                signal_rotation_index = (signal_rotation_index + 1) % 4\n",
    "                max_dist = max_distances[signal_rotation_index]\n",
    "                signal_states[signal_rotation_index] = 'GREEN'\n",
    "                green_time = 60 if max_dist > 250 else int(6 * (max_dist // 25))\n",
    "                green_time = max(green_time, 10)  # Minimum 10 seconds\n",
    "                signal_timers[signal_rotation_index] = green_time\n",
    "                signal_durations[signal_rotation_index] = green_time\n",
    "            else:\n",
    "                signal_timers[signal_rotation_index] = yellow_duration\n",
    "                signal_durations[signal_rotation_index] = yellow_duration\n",
    "\n",
    "    # Prepare Signals Frame\n",
    "    signals_frame = np.zeros((720, 200, 3), dtype=np.uint8) + 50\n",
    "    for idx in range(4):\n",
    "        y = idx * 180 + 50\n",
    "        # Draw Lights\n",
    "        for i, color in enumerate(['RED', 'YELLOW', 'GREEN']):\n",
    "            center = (100, y + i * 40)\n",
    "            radius = 15\n",
    "            light_color = colors[color] if signal_states[idx] == color else (30, 30, 30)\n",
    "            cv2.circle(signals_frame, center, radius, light_color, -1)\n",
    "\n",
    "        # Timer Text\n",
    "        txt = str(signal_timers[idx]) if signal_states[idx] != 'RED' else f\"In {sum(signal_timers[:idx] + signal_timers[idx+1:])}s\"\n",
    "        cv2.putText(signals_frame, txt, (70, y + 140), font, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "    # Combine all video frames\n",
    "    top_row = np.hstack((frames[0], frames[1]))\n",
    "    bottom_row = np.hstack((frames[2], frames[3]))\n",
    "    combined_frame = np.vstack((top_row, bottom_row))\n",
    "\n",
    "    # Resize signals_frame to match height\n",
    "    signals_frame = cv2.resize(signals_frame, (200, combined_frame.shape[0]))\n",
    "\n",
    "    final_display = np.hstack((combined_frame, signals_frame))\n",
    "    cv2.imshow(\"Traffic Management System\", final_display)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "for cap in caps:\n",
    "    cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b67a2b",
   "metadata": {},
   "source": [
    "# Working Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fa7a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['57.9', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['55.8', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['54.2', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['52.6', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['51.0', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['49.4', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['47.7', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['46.1', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['44.5', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['42.9', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['41.3', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['39.7', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['38.1', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['36.4', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['34.8', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['33.3', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['31.7', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['30.1', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['28.5', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['26.9', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['25.3', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['23.8', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['22.2', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['20.6', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['19.1', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['17.5', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['15.9', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['14.3', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['12.6', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['11.0', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['9.5', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['8.0', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['6.5', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['5.0', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['3.5', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['2.0', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['0.5', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['0.0', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [2, 0, 0, 0], Timers: ['3.1', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [2, 0, 0, 0], Timers: ['1.1', '0.0', '0.0', '0.0']\n",
      "Frame: 0, States: [2, 0, 0, 0], Timers: ['0.0', '0.0', '0.0', '0.0']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['0.0', '46.5', '0.0', '0.0']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['0.0', '44.9', '0.0', '0.0']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['0.0', '43.4', '0.0', '0.0']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['0.0', '42.0', '0.0', '0.0']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['0.0', '40.5', '0.0', '0.0']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['0.0', '39.0', '0.0', '0.0']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['0.0', '37.6', '0.0', '0.0']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['0.0', '36.1', '0.0', '0.0']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['0.0', '34.5', '0.0', '0.0']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['0.0', '33.0', '0.0', '0.0']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['0.0', '31.5', '0.0', '0.0']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['0.0', '30.0', '0.0', '0.0']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['0.0', '28.5', '0.0', '0.0']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['0.0', '27.1', '0.0', '0.0']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['0.0', '25.6', '0.0', '0.0']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['0.0', '24.0', '0.0', '0.0']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['0.0', '22.5', '0.0', '0.0']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['0.0', '21.0', '0.0', '0.0']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['0.0', '18.9', '0.0', '0.0']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['0.0', '16.4', '0.0', '0.0']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['0.0', '14.4', '0.0', '0.0']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['0.0', '12.7', '0.0', '0.0']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "import math\n",
    "from tracker import Tracker  # Assuming tracker.py is in the same directory\n",
    "\n",
    "# Load YOLO model\n",
    "model = YOLO('yolo12n.pt')  # Update with correct model path\n",
    "\n",
    "# Video file paths\n",
    "video_paths = [\n",
    "    'traffic1.mp4',  # North\n",
    "    'traffic2.mp4',  # East\n",
    "    'traffic3.mp4',  # South\n",
    "    'traffic4.mp4'   # West\n",
    "]\n",
    "\n",
    "# Load videos and check if they opened successfully\n",
    "videos = []\n",
    "for i, path in enumerate(video_paths):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video {path}\")\n",
    "        exit(1)\n",
    "    videos.append(cap)\n",
    "\n",
    "# Class list for vehicle types (subset of COCO classes)\n",
    "class_list = ['bicycle', 'car', 'motorcycle', 'bus', 'truck']\n",
    "valid_class_ids = [1, 2, 3, 6, 8]  # COCO indices: bicycle, car, motorcycle, bus, truck\n",
    "\n",
    "# Tracker instance\n",
    "tracker = Tracker()\n",
    "\n",
    "# Signal states: 0=Red, 1=Green, 2=Yellow\n",
    "signal_states = [1, 0, 0, 0]  # Start with frame 0 (North) green\n",
    "timers = [60, 0, 0, 0]  # Initial timer for green (60s), others 0\n",
    "current_frame = 0  # Start with frame 1 (index 0)\n",
    "last_switch_time = time.time()\n",
    "\n",
    "def draw_signals():\n",
    "    signal_frame = np.zeros((400, 800, 3), dtype=np.uint8)\n",
    "    colors = [(0, 0, 255), (0, 255, 0), (0, 255, 255)]  # Red, Green, Yellow\n",
    "    for i in range(4):\n",
    "        x, y = (i % 2) * 400, (i // 2) * 200\n",
    "        state = signal_states[i]\n",
    "        cv2.circle(signal_frame, (x + 50, y + 50), 40, colors[state], -1)\n",
    "        cv2.putText(signal_frame, f\"{timers[i]:.1f}s\", (x + 20, y + 150), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "    return signal_frame\n",
    "\n",
    "def calculate_max_distance_and_draw(frame, scan=True):\n",
    "    if not scan:\n",
    "        return frame, 0\n",
    "    \n",
    "    results = model.predict(frame, verbose=False)\n",
    "    max_dist = 0\n",
    "    objects_rect = []\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes.xyxy.cpu().numpy()\n",
    "        classes = r.boxes.cls.cpu().numpy()\n",
    "        for box, cls in zip(boxes, classes):\n",
    "            cls = int(cls)\n",
    "            if cls not in valid_class_ids:\n",
    "                continue\n",
    "            \n",
    "            class_idx = valid_class_ids.index(cls)\n",
    "            class_name = class_list[class_idx]\n",
    "            \n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            objects_rect.append([x1, y1, w, h])\n",
    "            \n",
    "            dist = frame.shape[0] - y1\n",
    "            max_dist = max(max_dist, dist)\n",
    "\n",
    "    tracked_objects = tracker.update(objects_rect)\n",
    "    \n",
    "    for obj in tracked_objects:\n",
    "        x, y, w, h, obj_id = obj\n",
    "        for box in boxes:\n",
    "            bx1, by1, bx2, by2 = map(int, box)\n",
    "            if bx1 == x and by1 == y:\n",
    "                for cls in classes:\n",
    "                    if int(cls) in valid_class_ids:\n",
    "                        class_idx = valid_class_ids.index(int(cls))\n",
    "                        class_name = class_list[class_idx]\n",
    "                        break\n",
    "                break\n",
    "        label = f\"{class_name} ID:{obj_id}\"\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, label, (x, y - 10), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    \n",
    "    return frame, max_dist\n",
    "\n",
    "def update_timers(max_distances):\n",
    "    global timers, signal_states, current_frame, last_switch_time\n",
    "    current_time = time.time()\n",
    "    elapsed = current_time - last_switch_time\n",
    "\n",
    "    # Update timers\n",
    "    for i in range(4):\n",
    "        if timers[i] > 0:\n",
    "            timers[i] = max(0, timers[i] - elapsed)  # Ensure timer doesn't go negative\n",
    "\n",
    "    # Debug print to monitor states and timers\n",
    "    print(f\"Frame: {current_frame}, States: {signal_states}, Timers: {[f'{t:.1f}' for t in timers]}\")\n",
    "\n",
    "    # Check state transitions\n",
    "    if signal_states[current_frame] == 1 and timers[current_frame] <= 0:\n",
    "        signal_states[current_frame] = 2  # Green to Yellow\n",
    "        timers[current_frame] = 5  # Yellow for 5 seconds\n",
    "    elif signal_states[current_frame] == 2 and timers[current_frame] <= 0:\n",
    "        signal_states[current_frame] = 0  # Yellow to Red\n",
    "        current_frame = (current_frame + 1) % 4  # Move to next frame\n",
    "        signal_states[current_frame] = 1  # Next frame to Green\n",
    "        max_dist = max_distances[current_frame]\n",
    "        timers[current_frame] = 60 if max_dist > 250 else max(6, (max_dist // 25) * 6)\n",
    "\n",
    "    last_switch_time = current_time\n",
    "\n",
    "while True:\n",
    "    frames = []\n",
    "    max_distances = []\n",
    "    for i, cap in enumerate(videos):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(f\"Warning: Failed to read frame from video {video_paths[i]}. Attempting to loop.\")\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(f\"Error: Could not loop video {video_paths[i]}. Exiting.\")\n",
    "                exit(1)\n",
    "        \n",
    "        if frame is None or frame.size == 0:\n",
    "            print(f\"Error: Invalid frame from video {video_paths[i]}. Exiting.\")\n",
    "            exit(1)\n",
    "        \n",
    "        frame = cv2.resize(frame, (400, 300))\n",
    "        \n",
    "        scan = signal_states[i] != 1\n",
    "        frame, max_dist = calculate_max_distance_and_draw(frame, scan)\n",
    "        max_distances.append(max_dist)\n",
    "        \n",
    "        cv2.putText(frame, f\"Max Dist: {max_dist:.0f}px\", (10, 30), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        frames.append(frame)\n",
    "\n",
    "    update_timers(max_distances)\n",
    "\n",
    "    top_row = np.hstack((frames[0], frames[1]))\n",
    "    bottom_row = np.hstack((frames[2], frames[3]))\n",
    "    video_grid = np.vstack((top_row, bottom_row))\n",
    "\n",
    "    signal_grid = draw_signals()\n",
    "\n",
    "    cv2.imshow('Traffic Videos', video_grid)\n",
    "    cv2.imshow('Traffic Signals', signal_grid)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "for cap in videos:\n",
    "    cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5043bd1d",
   "metadata": {},
   "source": [
    "# Timer is working perfectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "418db58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['57.9', '62.9', '109.9', '174.9']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['56.0', '61.0', '114.0', '179.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['54.4', '59.4', '112.4', '177.4']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['52.9', '57.9', '110.9', '175.9']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['51.3', '56.3', '109.3', '174.3']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['49.7', '54.7', '107.7', '172.7']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['48.0', '53.0', '112.0', '177.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['46.4', '51.4', '110.4', '175.4']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['44.9', '49.9', '102.9', '167.9']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['43.2', '48.2', '101.2', '166.2']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['41.7', '46.7', '99.7', '164.7']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['40.2', '45.2', '98.2', '163.2']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['38.6', '43.6', '96.6', '161.6']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['37.1', '42.1', '95.1', '160.1']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['35.5', '40.5', '87.5', '152.5']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['34.0', '39.0', '86.0', '151.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['32.5', '37.5', '90.5', '155.5']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['30.9', '35.9', '88.9', '153.9']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['29.4', '34.4', '87.4', '152.4']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['27.6', '32.6', '79.6', '144.6']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['26.1', '31.1', '84.1', '149.1']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['24.6', '29.6', '82.6', '147.6']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['23.0', '28.0', '81.0', '146.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['21.5', '26.5', '73.5', '138.5']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['20.0', '25.0', '78.0', '143.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['18.4', '23.4', '76.4', '141.4']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['16.8', '21.8', '86.8', '151.8']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['15.3', '20.3', '79.3', '144.3']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['13.7', '18.7', '71.7', '136.7']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['12.2', '17.2', '70.2', '135.2']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['10.6', '15.6', '80.6', '145.6']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['9.2', '14.2', '79.2', '144.2']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['7.5', '12.5', '65.5', '130.5']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['6.1', '11.1', '64.1', '129.1']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['4.7', '9.7', '62.7', '127.7']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['3.2', '8.2', '61.2', '126.2']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['1.4', '6.4', '59.4', '124.4']\n",
      "Frame: 0, States: [2, 0, 0, 0], Timers: ['5.0', '5.0', '58.0', '123.0']\n",
      "Frame: 0, States: [2, 0, 0, 0], Timers: ['3.1', '3.1', '56.1', '121.1']\n",
      "Frame: 0, States: [2, 0, 0, 0], Timers: ['1.2', '1.2', '54.2', '119.2']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['171.0', '48.0', '53.0', '118.0']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['169.5', '46.5', '51.5', '116.5']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['168.1', '45.1', '50.1', '115.1']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['166.6', '43.6', '48.6', '113.6']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['165.1', '42.1', '47.1', '112.1']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['163.6', '40.6', '45.6', '110.6']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['162.2', '39.2', '44.2', '109.2']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['160.8', '37.8', '42.8', '107.8']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['159.1', '36.1', '41.1', '106.1']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['157.7', '34.7', '39.7', '104.7']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['156.3', '33.3', '38.3', '103.3']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['154.8', '31.8', '36.8', '101.8']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['153.3', '30.3', '35.3', '100.3']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['151.8', '28.8', '33.8', '98.8']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['150.4', '27.4', '32.4', '97.4']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['148.9', '25.9', '30.9', '95.9']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['147.5', '24.5', '29.5', '94.5']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['146.0', '23.0', '28.0', '93.0']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['144.6', '21.6', '26.6', '91.6']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['137.1', '20.1', '25.1', '90.1']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['129.7', '18.7', '23.7', '88.7']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['134.2', '17.2', '22.2', '87.2']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['126.6', '15.6', '20.6', '85.6']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['131.2', '14.2', '19.2', '84.2']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['129.7', '12.7', '17.7', '82.7']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['128.3', '11.3', '16.3', '81.3']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['126.8', '9.8', '14.8', '79.8']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['125.4', '8.4', '13.4', '78.4']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['123.9', '6.9', '11.9', '76.9']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['122.5', '5.5', '10.5', '75.5']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['121.0', '4.0', '9.0', '74.0']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['119.5', '2.5', '7.5', '72.5']\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: ['118.0', '1.0', '6.0', '71.0']\n",
      "Frame: 1, States: [0, 2, 0, 0], Timers: ['117.0', '5.0', '5.0', '70.0']\n",
      "Frame: 1, States: [0, 2, 0, 0], Timers: ['115.1', '3.1', '3.1', '68.1']\n",
      "Frame: 1, States: [0, 2, 0, 0], Timers: ['113.2', '1.2', '1.2', '66.2']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['106.0', '141.0', '60.0', '65.0']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['104.6', '139.6', '58.6', '63.6']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['109.1', '150.1', '57.1', '62.1']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['107.6', '142.6', '55.6', '60.6']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['100.1', '135.1', '54.1', '59.1']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['98.6', '133.6', '52.6', '57.6']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['97.1', '138.1', '51.1', '56.1']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['101.7', '142.7', '49.7', '54.7']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['100.2', '135.2', '48.2', '53.2']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['98.8', '133.8', '46.8', '51.8']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['97.3', '132.3', '45.3', '50.3']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['95.9', '130.9', '43.9', '48.9']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['94.4', '135.4', '42.4', '47.4']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['93.0', '128.0', '41.0', '46.0']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['91.4', '126.4', '39.4', '44.4']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['89.9', '124.9', '37.9', '42.9']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['88.5', '123.5', '36.5', '41.5']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['87.0', '122.0', '35.0', '40.0']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['85.6', '120.6', '33.6', '38.6']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['84.1', '119.1', '32.1', '37.1']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['82.7', '117.7', '30.7', '35.7']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['81.3', '122.3', '29.3', '34.3']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['79.8', '120.8', '27.8', '32.8']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['78.4', '119.4', '26.4', '31.4']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['76.9', '117.9', '24.9', '29.9']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['75.5', '116.5', '23.5', '28.5']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['74.1', '115.1', '22.1', '27.1']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['72.5', '113.5', '20.5', '25.5']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['71.1', '112.1', '19.1', '24.1']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['69.6', '104.6', '17.6', '22.6']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['68.2', '103.2', '16.2', '21.2']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['66.7', '101.7', '14.7', '19.7']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['59.3', '94.3', '13.3', '18.3']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['57.9', '92.9', '11.9', '16.9']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['62.4', '97.4', '10.4', '15.4']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['61.0', '96.0', '9.0', '14.0']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['53.5', '88.5', '7.5', '12.5']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['52.1', '87.1', '6.1', '11.1']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['50.5', '85.5', '4.5', '9.5']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['48.9', '83.9', '2.9', '7.9']\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: ['47.5', '82.5', '1.5', '6.5']\n",
      "Frame: 2, States: [0, 0, 2, 0], Timers: ['46.0', '81.0', '5.0', '5.0']\n",
      "Frame: 2, States: [0, 0, 2, 0], Timers: ['44.1', '79.1', '3.1', '3.1']\n",
      "Frame: 2, States: [0, 0, 2, 0], Timers: ['42.2', '77.2', '1.2', '1.2']\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: ['41.0', '76.0', '141.0', '36.0']\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: ['39.6', '74.6', '139.6', '34.6']\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: ['38.1', '73.1', '138.1', '33.1']\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: ['36.7', '71.7', '136.7', '31.7']\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: ['35.2', '70.2', '135.2', '30.2']\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: ['33.8', '68.8', '133.8', '28.8']\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: ['32.3', '67.3', '132.3', '27.3']\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: ['30.9', '65.9', '130.9', '25.9']\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: ['29.4', '64.4', '129.4', '24.4']\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: ['27.8', '62.8', '127.8', '22.8']\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: ['26.4', '61.4', '126.4', '21.4']\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: ['24.8', '59.8', '124.8', '19.8']\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: ['23.3', '58.3', '123.3', '18.3']\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: ['21.8', '56.8', '121.8', '16.8']\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: ['20.3', '55.3', '120.3', '15.3']\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: ['18.9', '53.9', '118.9', '13.9']\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: ['17.4', '52.4', '117.4', '12.4']\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: ['15.9', '50.9', '115.9', '10.9']\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: ['14.4', '49.4', '114.4', '9.4']\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: ['12.9', '47.9', '112.9', '7.9']\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: ['11.4', '46.4', '111.4', '6.4']\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: ['9.5', '44.5', '109.5', '4.5']\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: ['7.8', '42.8', '89.8', '2.8']\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: ['6.1', '41.1', '88.1', '1.1']\n",
      "Frame: 3, States: [0, 0, 0, 2], Timers: ['5.0', '40.0', '87.0', '5.0']\n",
      "Frame: 3, States: [0, 0, 0, 2], Timers: ['2.7', '37.7', '84.7', '2.7']\n",
      "Frame: 3, States: [0, 0, 0, 2], Timers: ['0.6', '35.6', '82.6', '0.6']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['30.0', '35.0', '82.0', '141.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['28.3', '33.3', '80.3', '139.3']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['26.7', '31.7', '96.7', '155.7']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['25.1', '30.1', '83.1', '142.1']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['23.6', '28.6', '75.6', '134.6']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['22.0', '27.0', '92.0', '151.0']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['20.4', '25.4', '78.4', '137.4']\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: ['18.8', '23.8', '76.8', '135.8']\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "import math\n",
    "from tracker import Tracker\n",
    "\n",
    "# Load YOLO model\n",
    "model = YOLO('yolo12n.pt')  # Update with correct model path\n",
    "\n",
    "# Video file paths\n",
    "video_paths = [\n",
    "    'traffic1.mp4',  # North\n",
    "    'traffic2.mp4',  # East\n",
    "    'traffic3.mp4',  # South\n",
    "    'traffic4.mp4'   # West\n",
    "]\n",
    "\n",
    "# Load videos and check if they opened successfully\n",
    "videos = []\n",
    "for i, path in enumerate(video_paths):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video {path}\")\n",
    "        exit(1)\n",
    "    videos.append(cap)\n",
    "\n",
    "# Class list for vehicle types (subset of COCO classes)\n",
    "class_list = ['bicycle', 'car', 'motorcycle', 'bus', 'truck']\n",
    "valid_class_ids = [1, 2, 3, 6, 8]  # COCO indices: bicycle, car, motorcycle, bus, truck\n",
    "\n",
    "# Tracker instance\n",
    "tracker = Tracker()\n",
    "\n",
    "# Signal states: 0=Red, 1=Green, 2=Yellow\n",
    "signal_states = [1, 0, 0, 0]  # Start with frame 0 (North) green\n",
    "timers = [60, 0, 0, 0]  # Initial timer for green (60s), others to be calculated\n",
    "current_frame = 0  # Start with frame 0\n",
    "last_switch_time = time.time()\n",
    "\n",
    "def draw_signals():\n",
    "    signal_frame = np.zeros((400, 800, 3), dtype=np.uint8)\n",
    "    colors = [(0, 0, 255), (0, 255, 0), (0, 255, 255)]  # Red, Green, Yellow\n",
    "    for i in range(4):\n",
    "        x, y = (i % 2) * 400, (i // 2) * 200\n",
    "        state = signal_states[i]\n",
    "        cv2.circle(signal_frame, (x + 50, y + 50), 40, colors[state], -1)\n",
    "        cv2.putText(signal_frame, f\"{timers[i]:.1f}s\", (x + 20, y + 150), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "    return signal_frame\n",
    "\n",
    "def calculate_max_distance_and_draw(frame, scan=True):\n",
    "    if not scan:\n",
    "        return frame, 0\n",
    "    \n",
    "    results = model.predict(frame, verbose=False)\n",
    "    max_dist = 0\n",
    "    objects_rect = []\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes.xyxy.cpu().numpy()\n",
    "        classes = r.boxes.cls.cpu().numpy()\n",
    "        for box, cls in zip(boxes, classes):\n",
    "            cls = int(cls)\n",
    "            if cls not in valid_class_ids:\n",
    "                continue\n",
    "            \n",
    "            class_idx = valid_class_ids.index(cls)\n",
    "            class_name = class_list[class_idx]\n",
    "            \n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            objects_rect.append([x1, y1, w, h])\n",
    "            \n",
    "            dist = frame.shape[0] - y1\n",
    "            max_dist = max(max_dist, dist)\n",
    "\n",
    "    tracked_objects = tracker.update(objects_rect)\n",
    "    \n",
    "    for obj in tracked_objects:\n",
    "        x, y, w, h, obj_id = obj\n",
    "        for box in boxes:\n",
    "            bx1, by1, bx2, by2 = map(int, box)\n",
    "            if bx1 == x and by1 == y:\n",
    "                for cls in classes:\n",
    "                    if int(cls) in valid_class_ids:\n",
    "                        class_idx = valid_class_ids.index(int(cls))\n",
    "                        class_name = class_list[class_idx]\n",
    "                        break\n",
    "                break\n",
    "        label = f\"{class_name} ID:{obj_id}\"\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, label, (x, y - 10), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    \n",
    "    return frame, max_dist\n",
    "\n",
    "def update_timers(max_distances):\n",
    "    global timers, signal_states, current_frame, last_switch_time\n",
    "    current_time = time.time()\n",
    "    elapsed = current_time - last_switch_time\n",
    "\n",
    "    # Update timers for green and yellow\n",
    "    for i in range(4):\n",
    "        if signal_states[i] in [1, 2]:  # Green or Yellow\n",
    "            timers[i] = max(0, timers[i] - elapsed)\n",
    "\n",
    "    # Handle state transitions\n",
    "    if signal_states[current_frame] == 1 and timers[current_frame] <= 0:\n",
    "        signal_states[current_frame] = 2  # Green to Yellow\n",
    "        timers[current_frame] = 5  # Yellow for 5 seconds\n",
    "    elif signal_states[current_frame] == 2 and timers[current_frame] <= 0:\n",
    "        signal_states[current_frame] = 0  # Yellow to Red\n",
    "        current_frame = (current_frame + 1) % 4  # Move to next frame\n",
    "        signal_states[current_frame] = 1  # Next frame to Green\n",
    "        max_dist = max_distances[current_frame]\n",
    "        green_duration = 60 if max_dist > 250 else max(6, (max_dist // 25) * 6)\n",
    "        timers[current_frame] = green_duration\n",
    "\n",
    "    # Calculate red light timers (time until green)\n",
    "    total_cycle_time = 0\n",
    "    for i in range(4):\n",
    "        if signal_states[i] == 1:  # Green\n",
    "            total_cycle_time += timers[i] + 5  # Remaining green + yellow\n",
    "        elif signal_states[i] == 2:  # Yellow\n",
    "            total_cycle_time += timers[i]  # Remaining yellow\n",
    "\n",
    "    for i in range(1, 4):  # Calculate for red lights ahead in sequence\n",
    "        idx = (current_frame + i) % 4\n",
    "        if signal_states[idx] == 0:  # Red\n",
    "            wait_time = total_cycle_time\n",
    "            for j in range(i):\n",
    "                prev_idx = (current_frame + j) % 4\n",
    "                if prev_idx != current_frame:  # Skip current green/yellow\n",
    "                    max_dist = max_distances[prev_idx]\n",
    "                    green_duration = 60 if max_dist > 250 else max(6, (max_dist // 25) * 6)\n",
    "                    wait_time += green_duration + 5  # Add green + yellow for each prior frame\n",
    "            timers[idx] = wait_time\n",
    "\n",
    "    # Debug output\n",
    "    print(f\"Frame: {current_frame}, States: {signal_states}, Timers: {[f'{t:.1f}' for t in timers]}\")\n",
    "    last_switch_time = current_time\n",
    "\n",
    "while True:\n",
    "    frames = []\n",
    "    max_distances = []\n",
    "    for i, cap in enumerate(videos):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(f\"Warning: Failed to read frame from video {video_paths[i]}. Attempting to loop.\")\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(f\"Error: Could not loop video {video_paths[i]}. Exiting.\")\n",
    "                exit(1)\n",
    "        \n",
    "        if frame is None or frame.size == 0:\n",
    "            print(f\"Error: Invalid frame from video {video_paths[i]}. Exiting.\")\n",
    "            exit(1)\n",
    "        \n",
    "        frame = cv2.resize(frame, (400, 300))\n",
    "        \n",
    "        scan = signal_states[i] != 1\n",
    "        frame, max_dist = calculate_max_distance_and_draw(frame, scan)\n",
    "        max_distances.append(max_dist)\n",
    "        \n",
    "        cv2.putText(frame, f\"Max Dist: {max_dist:.0f}px\", (10, 30), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        frames.append(frame)\n",
    "\n",
    "    update_timers(max_distances)\n",
    "\n",
    "    top_row = np.hstack((frames[0], frames[1]))\n",
    "    bottom_row = np.hstack((frames[2], frames[3]))\n",
    "    video_grid = np.vstack((top_row, bottom_row))\n",
    "\n",
    "    signal_grid = draw_signals()\n",
    "\n",
    "    cv2.imshow('Traffic Videos', video_grid)\n",
    "    cv2.imshow('Traffic Signals', signal_grid)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "for cap in videos:\n",
    "    cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e4e49f",
   "metadata": {},
   "source": [
    "# Final Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c58d47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame: 0, States: [1, 0, 0, 0], Timers: [57, 62, 109, 174]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [55, 60, 113, 178]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [54, 59, 112, 177]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [52, 57, 110, 175]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [51, 56, 109, 174]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [49, 54, 107, 172]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [48, 53, 112, 177]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [46, 51, 110, 175]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [45, 50, 103, 168]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [43, 48, 101, 166]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [42, 47, 100, 165]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [40, 45, 98, 163]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [39, 44, 97, 162]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [37, 42, 95, 160]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [36, 41, 88, 153]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [34, 39, 86, 151]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [33, 38, 91, 156]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [31, 36, 89, 154]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [30, 35, 88, 153]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [28, 33, 80, 145]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [27, 32, 85, 150]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [25, 30, 83, 148]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [24, 29, 82, 147]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [22, 27, 74, 139]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [21, 26, 79, 144]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [19, 24, 77, 142]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [18, 23, 88, 153]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [16, 21, 80, 145]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [15, 20, 73, 138]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [13, 18, 71, 136]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [12, 17, 82, 147]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [10, 15, 80, 145]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [9, 14, 67, 132]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [7, 12, 65, 130]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [6, 11, 64, 129]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [5, 10, 63, 128]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [3, 8, 61, 126]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [2, 7, 60, 125]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [0, 5, 58, 123]\n",
      "Frame: 0, States: [2, 0, 0, 0], Timers: [5, 5, 58, 123]\n",
      "Frame: 0, States: [2, 0, 0, 0], Timers: [3, 3, 56, 121]\n",
      "Frame: 0, States: [2, 0, 0, 0], Timers: [1, 1, 54, 119]\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: [171, 48, 53, 118]\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: [169, 46, 51, 116]\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: [168, 45, 50, 115]\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: [166, 43, 48, 113]\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: [165, 42, 47, 112]\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: [163, 40, 45, 110]\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: [162, 39, 44, 109]\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: [160, 37, 42, 107]\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: [159, 36, 41, 106]\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: [157, 34, 39, 104]\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: [156, 33, 38, 103]\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: [154, 31, 36, 101]\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: [153, 30, 35, 100]\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: [151, 28, 33, 98]\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: [150, 27, 32, 97]\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: [148, 25, 30, 95]\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: [147, 24, 29, 94]\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: [139, 22, 27, 92]\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: [132, 21, 26, 91]\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: [136, 19, 24, 89]\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: [129, 18, 23, 88]\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: [133, 16, 21, 86]\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: [132, 15, 20, 85]\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: [130, 13, 18, 83]\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: [129, 12, 17, 82]\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: [127, 10, 15, 80]\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: [126, 9, 14, 79]\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: [125, 8, 13, 78]\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: [123, 6, 11, 76]\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: [122, 5, 10, 75]\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: [120, 3, 8, 73]\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: [119, 2, 7, 72]\n",
      "Frame: 1, States: [0, 1, 0, 0], Timers: [117, 0, 5, 70]\n",
      "Frame: 1, States: [0, 2, 0, 0], Timers: [117, 5, 5, 70]\n",
      "Frame: 1, States: [0, 2, 0, 0], Timers: [108, 2, 2, 67]\n",
      "Frame: 1, States: [0, 2, 0, 0], Timers: [107, 1, 1, 66]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [112, 153, 60, 65]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [110, 145, 58, 63]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [102, 137, 56, 61]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [101, 136, 55, 60]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [99, 140, 53, 58]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [104, 145, 52, 57]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [103, 138, 51, 56]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [101, 136, 49, 54]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [100, 135, 48, 53]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [98, 133, 46, 51]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [97, 138, 45, 50]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [95, 130, 43, 48]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [93, 128, 41, 46]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [92, 127, 40, 45]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [90, 125, 38, 43]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [89, 124, 37, 42]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [87, 122, 35, 40]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [86, 121, 34, 39]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [85, 120, 33, 38]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [83, 124, 31, 36]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [82, 123, 30, 35]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [80, 121, 28, 33]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [79, 120, 27, 32]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [77, 118, 25, 30]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [76, 117, 24, 29]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [74, 115, 22, 27]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [73, 114, 21, 26]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [71, 106, 19, 24]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [70, 105, 18, 23]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [68, 103, 16, 21]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [61, 96, 15, 20]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [60, 95, 14, 19]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [64, 99, 12, 17]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [63, 98, 11, 16]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [55, 90, 9, 14]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [54, 89, 8, 13]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [52, 87, 6, 11]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [51, 86, 5, 10]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [49, 84, 3, 8]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [48, 83, 2, 7]\n",
      "Frame: 2, States: [0, 0, 1, 0], Timers: [46, 81, 0, 5]\n",
      "Frame: 2, States: [0, 0, 2, 0], Timers: [46, 81, 5, 5]\n",
      "Frame: 2, States: [0, 0, 2, 0], Timers: [44, 79, 3, 3]\n",
      "Frame: 2, States: [0, 0, 2, 0], Timers: [42, 77, 1, 1]\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: [41, 76, 141, 36]\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: [39, 74, 139, 34]\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: [37, 72, 137, 32]\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: [36, 71, 136, 31]\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: [34, 69, 134, 29]\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: [33, 68, 133, 28]\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: [32, 67, 132, 27]\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: [30, 65, 130, 25]\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: [29, 64, 129, 24]\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: [27, 62, 127, 22]\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: [26, 61, 126, 21]\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: [24, 59, 124, 19]\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: [23, 58, 123, 18]\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: [21, 56, 121, 16]\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: [20, 55, 120, 15]\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: [18, 53, 118, 13]\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: [17, 52, 117, 12]\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: [15, 50, 115, 10]\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: [14, 49, 114, 9]\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: [12, 47, 112, 7]\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: [11, 46, 93, 6]\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: [9, 44, 91, 4]\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: [8, 43, 90, 3]\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: [6, 41, 88, 1]\n",
      "Frame: 3, States: [0, 0, 0, 1], Timers: [5, 40, 87, 0]\n",
      "Frame: 3, States: [0, 0, 0, 2], Timers: [5, 40, 87, 5]\n",
      "Frame: 3, States: [0, 0, 0, 2], Timers: [3, 38, 85, 3]\n",
      "Frame: 3, States: [0, 0, 0, 2], Timers: [1, 36, 101, 1]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [30, 35, 88, 147]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [28, 33, 80, 139]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [27, 32, 97, 156]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [25, 30, 83, 142]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [24, 29, 82, 141]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [22, 27, 80, 139]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [21, 26, 79, 138]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [19, 24, 77, 136]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [18, 23, 76, 135]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [16, 21, 74, 133]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [15, 20, 73, 132]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [13, 18, 65, 124]\n",
      "Frame: 0, States: [1, 0, 0, 0], Timers: [12, 17, 76, 135]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "import math\n",
    "from tracker import Tracker\n",
    "\n",
    "# Load YOLO model\n",
    "model = YOLO('yolo12n.pt')  # Update with correct model path\n",
    "\n",
    "# Video file paths\n",
    "video_paths = [\n",
    "    'traffic1.mp4',  # North\n",
    "    'traffic2.mp4',  # East\n",
    "    'traffic3.mp4',  # South\n",
    "    'traffic4.mp4'   # West\n",
    "]\n",
    "\n",
    "# Load videos and check if they opened successfully\n",
    "videos = []\n",
    "for i, path in enumerate(video_paths):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video {path}\")\n",
    "        exit(1)\n",
    "    videos.append(cap)\n",
    "\n",
    "# Class list for vehicle types (subset of COCO classes)\n",
    "class_list = ['bicycle', 'car', 'motorcycle', 'bus', 'truck']\n",
    "valid_class_ids = [1, 2, 3, 6, 8]  # COCO indices: bicycle, car, motorcycle, bus, truck\n",
    "\n",
    "# Tracker instance\n",
    "tracker = Tracker()\n",
    "\n",
    "# Signal states: 0=Red, 1=Green, 2=Yellow\n",
    "signal_states = [1, 0, 0, 0]  # Start with frame 0 (North) green\n",
    "timers = [60, 0, 0, 0]  # Initial timer for green (60s), others to be calculated\n",
    "current_frame = 0  # Start with frame 0\n",
    "last_switch_time = time.time()\n",
    "\n",
    "def draw_signals():\n",
    "    signal_frame = np.zeros((400, 800, 3), dtype=np.uint8)\n",
    "    colors = [(0, 0, 255), (0, 255, 0), (0, 255, 255)]  # Red, Green, Yellow\n",
    "    for i in range(4):\n",
    "        x, y = (i % 2) * 400, (i // 2) * 200\n",
    "        state = signal_states[i]\n",
    "        cv2.circle(signal_frame, (x + 50, y + 50), 40, colors[state], -1)\n",
    "        # Display timer as integer\n",
    "        cv2.putText(signal_frame, f\"{int(timers[i])}s\", (x + 20, y + 150), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "    return signal_frame\n",
    "\n",
    "def calculate_max_distance_and_draw(frame, scan=True):\n",
    "    if not scan:\n",
    "        return frame, 0\n",
    "    \n",
    "    results = model.predict(frame, verbose=False)\n",
    "    max_dist = 0\n",
    "    objects_rect = []\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes.xyxy.cpu().numpy()\n",
    "        classes = r.boxes.cls.cpu().numpy()\n",
    "        for box, cls in zip(boxes, classes):\n",
    "            cls = int(cls)\n",
    "            if cls not in valid_class_ids:\n",
    "                continue\n",
    "            \n",
    "            class_idx = valid_class_ids.index(cls)\n",
    "            class_name = class_list[class_idx]\n",
    "            \n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            objects_rect.append([x1, y1, w, h])\n",
    "            \n",
    "            dist = frame.shape[0] - y1\n",
    "            max_dist = max(max_dist, dist)\n",
    "\n",
    "    tracked_objects = tracker.update(objects_rect)\n",
    "    \n",
    "    for obj in tracked_objects:\n",
    "        x, y, w, h, obj_id = obj\n",
    "        for box in boxes:\n",
    "            bx1, by1, bx2, by2 = map(int, box)\n",
    "            if bx1 == x and by1 == y:\n",
    "                for cls in classes:\n",
    "                    if int(cls) in valid_class_ids:\n",
    "                        class_idx = valid_class_ids.index(int(cls))\n",
    "                        class_name = class_list[class_idx]\n",
    "                        break\n",
    "                break\n",
    "        label = f\"{class_name} ID:{obj_id}\"\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, label, (x, y - 10), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    \n",
    "    return frame, max_dist\n",
    "\n",
    "def update_timers(max_distances):\n",
    "    global timers, signal_states, current_frame, last_switch_time\n",
    "    current_time = time.time()\n",
    "    elapsed = current_time - last_switch_time\n",
    "\n",
    "    # Update timers for green and yellow\n",
    "    for i in range(4):\n",
    "        if signal_states[i] in [1, 2]:  # Green or Yellow\n",
    "            timers[i] = max(0, timers[i] - elapsed)\n",
    "\n",
    "    # Handle state transitions\n",
    "    if signal_states[current_frame] == 1 and timers[current_frame] <= 0:\n",
    "        signal_states[current_frame] = 2  # Green to Yellow\n",
    "        timers[current_frame] = 5  # Yellow for 5 seconds\n",
    "    elif signal_states[current_frame] == 2 and timers[current_frame] <= 0:\n",
    "        signal_states[current_frame] = 0  # Yellow to Red\n",
    "        current_frame = (current_frame + 1) % 4  # Move to next frame\n",
    "        signal_states[current_frame] = 1  # Next frame to Green\n",
    "        max_dist = max_distances[current_frame]\n",
    "        green_duration = 60 if max_dist > 250 else max(6, (max_dist // 25) * 6)\n",
    "        timers[current_frame] = green_duration\n",
    "\n",
    "    # Calculate red light timers (time until green)\n",
    "    total_cycle_time = 0\n",
    "    for i in range(4):\n",
    "        if signal_states[i] == 1:  # Green\n",
    "            total_cycle_time += timers[i] + 5  # Remaining green + yellow\n",
    "        elif signal_states[i] == 2:  # konserwYellow\n",
    "            total_cycle_time += timers[i]  # Remaining yellow\n",
    "\n",
    "    for i in range(1, 4):  # Calculate for red lights ahead in sequence\n",
    "        idx = (current_frame + i) % 4\n",
    "        if signal_states[idx] == 0:  # Red\n",
    "            wait_time = total_cycle_time\n",
    "            for j in range(i):\n",
    "                prev_idx = (current_frame + j) % 4\n",
    "                if prev_idx != current_frame:  # Skip current green/yellow\n",
    "                    max_dist = max_distances[prev_idx]\n",
    "                    green_duration = 60 if max_dist > 250 else max(6, (max_dist // 25) * 6)\n",
    "                    wait_time += green_duration + 5  # Add green + yellow for each prior frame\n",
    "            timers[idx] = wait_time\n",
    "\n",
    "    # Debug output with integer timers\n",
    "    print(f\"Frame: {current_frame}, States: {signal_states}, Timers: {[int(t) for t in timers]}\")\n",
    "    last_switch_time = current_time\n",
    "\n",
    "while True:\n",
    "    frames = []\n",
    "    max_distances = []\n",
    "    for i, cap in enumerate(videos):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(f\"Warning: Failed to read frame from video {video_paths[i]}. Attempting to loop.\")\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(f\"Error: Could not loop video {video_paths[i]}. Exiting.\")\n",
    "                exit(1)\n",
    "        \n",
    "        if frame is None or frame.size == 0:\n",
    "            print(f\"Error: Invalid frame from video {video_paths[i]}. Exiting.\")\n",
    "            exit(1)\n",
    "        \n",
    "        frame = cv2.resize(frame, (400, 300))\n",
    "        \n",
    "        scan = signal_states[i] != 1\n",
    "        frame, max_dist = calculate_max_distance_and_draw(frame, scan)\n",
    "        max_distances.append(max_dist)\n",
    "        \n",
    "        cv2.putText(frame, f\"Max Dist: {max_dist:.0f}px\", (10, 30), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "        frames.append(frame)\n",
    "\n",
    "    update_timers(max_distances)\n",
    "\n",
    "    top_row = np.hstack((frames[0], frames[1]))\n",
    "    bottom_row = np.hstack((frames[2], frames[3]))\n",
    "    video_grid = np.vstack((top_row, bottom_row))\n",
    "\n",
    "    signal_grid = draw_signals()\n",
    "\n",
    "    cv2.imshow('Traffic Videos', video_grid)\n",
    "    cv2.imshow('Traffic Signals', signal_grid)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Cleanup\n",
    "for cap in videos:\n",
    "    cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
